{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "config = [\n",
    "    \n",
    "\"--experimentdir\", \"/home/schindlera/experiments/ismir2020_reviews/\",\n",
    "\"--modeldir\"     , \"/home/schindlera/experiments/ismir2020_reviews/\",\n",
    "    \n",
    "\"--relcontent\"   , \"rel_content_emb_tag_lsi\", \n",
    "\"--audio\"        , \"melspec_128_10seconds_2ch_norm\", \n",
    "    \n",
    "\"--model\"        , \"model.m1_3\",     \n",
    "\"--gpu\"          , \"0\",\n",
    "    \n",
    "\"--loss\"         , \"original\", \n",
    "\"--lossagg\"      , \"max\", \n",
    "\"--margin\"       , \"1.0\", \n",
    "\"--uppersim\"     , \"0.90\", \n",
    "    \n",
    "\"--finaldim\"     , \"128\", \n",
    "\"--epochs\"       , \"10\", \n",
    "\"--learnrate\"    , \"0.0001\",\n",
    "\"--batchsize\"    , \"1000\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--relcontent',    type=str)\n",
    "parser.add_argument('--model',         type=str)\n",
    "parser.add_argument('--audio',         type=str)\n",
    "parser.add_argument('--experimentdir', type=str)\n",
    "parser.add_argument('--modeldir',      type=str)\n",
    "parser.add_argument('--gpu',           type=int)\n",
    "parser.add_argument('--finaldim',      type=int)\n",
    "parser.add_argument('--lossagg',       type=str, default=\"min\")\n",
    "parser.add_argument('--loss',          type=str, default=\"original\")\n",
    "parser.add_argument('--batchsize',     type=int, default=1000)\n",
    "parser.add_argument('--margin',        type=float)\n",
    "parser.add_argument('--learnrate',     type=float, default=0.0001)\n",
    "parser.add_argument('--uppersim',      type=float)\n",
    "parser.add_argument('--epochs',        type=int, default=100)\n",
    "parser.add_argument(\"--log-level\", default=logging.DEBUG, type=lambda x: getattr(logger, x), help=\"Configure the logger level.\")\n",
    "\n",
    "if sys.argv[0].find(\"ipykernel_launcher\") != -1:\n",
    "    args = parser.parse_args(config)\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# control random processes\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def prepare_model_dir(model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Initialize Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Init Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 21:39:32 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-22 21:39:32 - experiment.py - INFO - | STARTING EXPERIMENT                                              |\n",
      "2020-04-22 21:39:32 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-22 21:39:32 - experiment.py - INFO - Logger initialized\n",
      "2020-04-22 21:39:32 - experiment.py - INFO - Initializing model experiment directory\n",
      "2020-04-22 21:39:32 - experiment.py - INFO - Initializing logger filehandler\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(\"experiment.py\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| STARTING EXPERIMENT                                              |\")\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"Logger initialized\")\n",
    "\n",
    "logger.info(\"Initializing model experiment directory\")\n",
    "model_storage_path = prepare_model_dir(args.modeldir)\n",
    "\n",
    "logger.info(\"Initializing logger filehandler\")\n",
    "fh = logging.FileHandler(\"%s/experiment.log\" % args.modeldir)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Print Experiment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 21:39:36 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | EXPERIMENT:                                                      |\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Experiment directory              : /home/schindlera/experiments/ismir2020_reviews/\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Model-Directory                   : /home/schindlera/experiments/ismir2020_reviews/\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Related content filename          : rel_content_emb_tag_lsi\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Audio-Features filename           : melspec_128_10seconds_2ch_norm\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | GPU                               : 0\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Model                             : model.m1_3\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Dimensions Final Music-Embeddings : 128\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Loss                              : original\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Loss-Aggregation                  : max\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Upper Sim                         : 0.990000\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Margin                            : 1.000000\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Learn Rate                        : 0.000001\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Batch Size                        : 2000\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - | Num Epochs                        : 1\n",
      "2020-04-22 21:39:36 - experiment.py - INFO - +------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| EXPERIMENT:                                                      |\")\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Experiment directory              : %s\"           % args.experimentdir)\n",
    "logger.info(\"| Model-Directory                   : %s\"           % args.modeldir)\n",
    "logger.info(\"| Related content filename          : %s\"           % args.relcontent)\n",
    "logger.info(\"| Audio-Features filename           : %s\"           % args.audio)\n",
    "logger.info(\"| GPU                               : %d\"           % args.gpu)\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Model                             : %s\"           % args.model)\n",
    "logger.info(\"| Dimensions Final Music-Embeddings : %d\"           % args.finaldim)\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Loss                              : %s\"           % args.loss)\n",
    "logger.info(\"| Loss-Aggregation                  : %s\"           % args.lossagg)\n",
    "logger.info(\"| Upper Sim                         : %f\"           % args.uppersim)\n",
    "logger.info(\"| Margin                            : %f\"           % args.margin)\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Learn Rate                        : %f\"           % args.learnrate)\n",
    "logger.info(\"| Batch Size                        : %d\"           % args.batchsize)\n",
    "logger.info(\"| Num Epochs                        : %d\"           % args.epochs)\n",
    "logger.info(\"+------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Store configuration for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open(\"%s/experiment_arguments.json\" % args.modeldir, 'w') as json_file:\n",
    "    args_json = json.dump(vars(args), json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 21:39:40 - experiment.py - INFO - * Load Audio Data\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"* Load Audio Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Load Audio Data - Train Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 21:39:48 - experiment.py - INFO - * Load Audio Data - Train Partition\n",
      "CPU times: user 4min 13s, sys: 4min 58s, total: 9min 11s\n",
      "Wall time: 10min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logger.info(\"* Load Audio Data - Train Partition\")\n",
    "\n",
    "# load partition trackid file\n",
    "par_file           = \"%s/eval_partition_trackids_train.csv\" % (args.experimentdir)\n",
    "par_trackids_train = pd.read_csv(par_file, header=None, index_col=0)\n",
    "\n",
    "# load audio content\n",
    "par_filename_audio_train = \"%s/%s_train.npz\" % (args.experimentdir, args.audio)\n",
    "\n",
    "with np.load(par_filename_audio_train, allow_pickle=True) as npz:\n",
    "    data_audio_train      = npz[\"data\"]\n",
    "    track_ids_audio_train = npz[\"track_ids\"].astype(str)\n",
    "    \n",
    "lookup_audio_train = pd.DataFrame(np.arange(track_ids_audio_train.shape[0], dtype=int), \n",
    "                                  index   = track_ids_audio_train, \n",
    "                                  columns = [\"feature_line_nr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# CHECK: ids and data have same length\n",
    "assert(data_audio_train.shape[0] == track_ids_audio_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#par_trackids_train.index.values == track_ids_audio_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Load Audio Data - Validation Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 21:50:58 - experiment.py - INFO - * Load Audio Data - Validation Partition\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"* Load Audio Data - Validation Partition\")\n",
    "\n",
    "# load partition trackid file\n",
    "par_file         = \"%s/eval_partition_trackids_val.csv\" % (args.experimentdir)\n",
    "par_trackids_val = pd.read_csv(par_file, header=None, index_col=0)\n",
    "\n",
    "# load audio content\n",
    "par_filename_audio_val = \"%s/%s_val.npz\" % (args.experimentdir, args.audio)\n",
    "\n",
    "with np.load(par_filename_audio_val, allow_pickle=True) as npz:\n",
    "    data_audio_val      = npz[\"data\"]\n",
    "    track_ids_audio_val = npz[\"track_ids\"].astype(str)\n",
    "    \n",
    "lookup_audio_val = pd.DataFrame(np.arange(track_ids_audio_val.shape[0], dtype=int), \n",
    "                                  index   = track_ids_audio_val, \n",
    "                                  columns = [\"feature_line_nr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# CHECK: ids and data have same length\n",
    "assert(data_audio_val.shape[0] == track_ids_audio_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 21:51:05 - experiment.py - INFO - Num instances - audio data train : 247480\n",
      "2020-04-22 21:51:05 - experiment.py - INFO - Num instances - audio data val   : 2500\n",
      "2020-04-22 21:51:05 - experiment.py - INFO - data_audio dimensions            : (247480, 128, 880, 2)\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Num instances - audio data train : %d\" % data_audio_train.shape[0])\n",
    "logger.info(\"Num instances - audio data val   : %d\" % data_audio_val.shape[0])\n",
    "logger.info(\"data_audio dimensions            : %s\" % str(data_audio_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Related Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 21:51:05 - experiment.py - INFO - * Load Related Content Embeddings\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"* Load Related Content Embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Train Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "par_filename_relcontent_train = \"%s/%s_train.npz\" % (args.experimentdir, args.relcontent)\n",
    "\n",
    "with np.load(par_filename_relcontent_train, allow_pickle=True) as npz:\n",
    "    data_relcontent_train     = npz[\"data\"]\n",
    "    trackids_relcontent_train = npz[\"trackids\"].astype(str)\n",
    "\n",
    "lookup_relcontent_train = pd.DataFrame(np.arange(trackids_relcontent_train.shape[0], dtype=int), \n",
    "                                       index   = trackids_relcontent_train, \n",
    "                                       columns = [\"feature_line_nr\"])\n",
    "\n",
    "# CHECK: ids and data have same length\n",
    "assert(data_relcontent_train.shape[0] == trackids_relcontent_train.shape[0])\n",
    "\n",
    "# CHECK: ids of text and audio are aligned\n",
    "#assert((track_ids_text == track_ids_audio).sum() == track_ids_audio.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Validation Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "par_filename_relcontent_val = \"%s/%s_val.npz\" % (args.experimentdir, args.relcontent)\n",
    "\n",
    "with np.load(par_filename_relcontent_val, allow_pickle=True) as npz:\n",
    "    data_relcontent_val     = npz[\"data\"]\n",
    "    trackids_relcontent_val = npz[\"trackids\"].astype(str)\n",
    "\n",
    "lookup_relcontent_val = pd.DataFrame(np.arange(trackids_relcontent_val.shape[0], dtype=int), \n",
    "                                       index   = trackids_relcontent_val, \n",
    "                                       columns = [\"feature_line_nr\"])\n",
    "\n",
    "# CHECK: ids and data have same length\n",
    "assert(data_relcontent_val.shape[0] == trackids_relcontent_val.shape[0])\n",
    "\n",
    "# CHECK: ids of text and audio are aligned\n",
    "#assert((track_ids_text == track_ids_audio).sum() == track_ids_audio.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 21:51:07 - experiment.py - INFO - Num instances - related content train : 247480\n",
      "2020-04-22 21:51:07 - experiment.py - INFO - Num instances - related content val   : 2500\n",
      "2020-04-22 21:51:07 - experiment.py - INFO - data_relcontent dimensions            : (247480, 340)\n",
      "2020-04-22 21:51:07 - experiment.py - INFO - TEXT_EMBEDDINGS_DIMENSIONS            : 340\n",
      "2020-04-22 21:51:07 - experiment.py - INFO - +------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Num instances - related content train : %d\" % data_relcontent_train.shape[0])\n",
    "logger.info(\"Num instances - related content val   : %d\" % data_relcontent_val.shape[0])\n",
    "logger.info(\"data_relcontent dimensions            : %s\" % str(data_relcontent_train.shape))\n",
    "logger.info(\"TEXT_EMBEDDINGS_DIMENSIONS            : %d\" % data_relcontent_train.shape[1])\n",
    "logger.info(\"+------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 21:51:07 - experiment.py - INFO - Partitions overview - train/val\n",
      "2020-04-22 21:51:07 - experiment.py - INFO - data_audio_train      dimensions    : (247480, 128, 880, 2)\n",
      "2020-04-22 21:51:07 - experiment.py - INFO - data_relcontent_train dimensions    : (247480, 340)\n",
      "2020-04-22 21:51:07 - experiment.py - INFO - data_audio_val        dimensions    : (2500, 128, 880, 2)\n",
      "2020-04-22 21:51:07 - experiment.py - INFO - data_relcontent_val   dimensions    : (2500, 340)\n",
      "2020-04-22 21:51:07 - experiment.py - INFO - +------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "TEXT_EMBEDDINGS_DIMENSIONS = data_relcontent_train.shape[1]\n",
    "\n",
    "logger.info(\"Partitions overview - train/val\")\n",
    "\n",
    "logger.info(\"data_audio_train      dimensions    : %s\" % str(data_audio_train.shape))\n",
    "logger.info(\"data_relcontent_train dimensions    : %s\" % str(data_relcontent_train.shape))\n",
    "logger.info(\"data_audio_val        dimensions    : %s\" % str(data_audio_val.shape))\n",
    "logger.info(\"data_relcontent_val   dimensions    : %s\" % str(data_relcontent_val.shape))\n",
    "logger.info(\"+------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class OnlineTripletLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, margin, upper_limit):\n",
    "        super(OnlineTripletLoss, self).__init__()\n",
    "        \n",
    "        self.margin      = margin\n",
    "        self.upper_limit = upper_limit\n",
    "\n",
    "    def cosine_similarity(self, x1, x2=None, eps=1e-8):\n",
    "        x2 = x1 if x2 is None else x2\n",
    "        w1 = x1.norm(p=2, dim=1, keepdim=True)\n",
    "        w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\n",
    "        return torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)\n",
    "\n",
    "    def forward(self, audio_embeddings, text_embdeeings):\n",
    "\n",
    "        # Get the pairwise distance matrix\n",
    "        pairwise_dists_text  = self.cosine_similarity(text_embdeeings)\n",
    "        pairwise_dists_audio = torch.cdist(audio_embeddings,audio_embeddings, p=2)\n",
    "\n",
    "        # create filter masks\n",
    "        max_pairwise_dist_audio = pairwise_dists_audio.max()\n",
    "\n",
    "        # positive bool mask\n",
    "        mask_positive = (pairwise_dists_text.fill_diagonal_(0) > self.upper_limit)\n",
    "\n",
    "        # negative bool mask\n",
    "        mask_negative = (1 - mask_positive.float()).fill_diagonal_(0)\n",
    "\n",
    "        if args.lossagg == \"max\":\n",
    "\n",
    "            audio_positive_dist       = pairwise_dists_audio * mask_positive.float()\n",
    "            hardest_positive_dist, _  = audio_positive_dist.max(dim=1, keepdims=True)\n",
    "\n",
    "        #elif args.lossagg == \"min\":\n",
    "        # \n",
    "        #    audio_positive_dist       = pairwise_dists_audio * mask_positive_bool\n",
    "        #    hardest_positive_dist, _  = audio_positive_dist.min(dim=1, keepdims=True)\n",
    "\n",
    "        # negative\n",
    "        max_audio_negative_dist, _ = pairwise_dists_audio.max(1, keepdim=True)\n",
    "        audio_negative_dist        = pairwise_dists_audio + max_audio_negative_dist * (1.0 - mask_negative)\n",
    "\n",
    "        hardest_negative_dist, _   = audio_negative_dist.min(dim=1, keepdims=True)\n",
    "        \n",
    "        # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "        delta = hardest_positive_dist - hardest_negative_dist\n",
    "        \n",
    "        #print(mask_positive)\n",
    "        \n",
    "        \n",
    "        delta = delta[mask_positive.any(axis=0),:]\n",
    "        #print(hardest_positive_dist.shape[0], delta.shape[0])\n",
    "\n",
    "        if   args.loss == \"original\"     : \n",
    "            triplet_loss = (delta + self.margin)\n",
    "            triplet_loss[triplet_loss < 0] = 0\n",
    "            triplet_loss = triplet_loss.mean()\n",
    "\n",
    "\n",
    "        #elif args.loss == \"logistic_sum\" : triplet_loss = tf.reduce_sum (tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "        #elif args.loss == \"logistic_mean\": triplet_loss = tf.reduce_mean(tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "        #elif args.loss == \"hinge_sum\"    : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.nn.relu(margin + delta)))\n",
    "        #elif args.loss == \"hinge_mean\"   : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.nn.relu(margin + delta)))\n",
    "        #elif args.loss == \"exp_sum\"      : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "        #elif args.loss == \"exp_mean\"     : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "        else: raise NotImplementedError\n",
    "\n",
    "        return triplet_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class NetKim2019(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NetKim2019, self).__init__()\n",
    "        \n",
    "        self.conv1      = nn.Conv2d(2,    16, kernel_size=5, stride=(2,1), padding=2)\n",
    "        self.conv2      = nn.Conv2d(16,   32, kernel_size=3, padding=1)\n",
    "        self.conv3      = nn.Conv2d(32,   64, kernel_size=3, padding=1)\n",
    "        self.conv4      = nn.Conv2d(64,   64, kernel_size=3, padding=1)\n",
    "        self.conv5      = nn.Conv2d(64,  128, kernel_size=3, padding=1)\n",
    "        self.conv6a     = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6b     = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.maxpool1   = nn.MaxPool2d((2,2))\n",
    "        self.maxpool2   = nn.MaxPool2d((2,2))\n",
    "        self.maxpool3   = nn.MaxPool2d((2,2))\n",
    "        self.maxpool4   = nn.MaxPool2d((2,2))\n",
    "        self.maxpool5   = nn.MaxPool2d((2,2))\n",
    "        \n",
    "        self.gap        = nn.AdaptiveMaxPool2d(1)\n",
    "                \n",
    "        self.dropout    = nn.Dropout()\n",
    "        self.fc_feature = nn.Linear(256, 256)\n",
    "        self.fc_output  = nn.Linear(256, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool5(x)\n",
    "        \n",
    "        x = self.conv6a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6b(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.shape[:2])\n",
    "\n",
    "        x = self.fc_feature(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc_output(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "#summary(model.cuda(), (2, 216, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## DataSet Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class MelSpecDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, audio_data, text_data, random_cropping=False):\n",
    "        self.audio_data      = audio_data\n",
    "        self.text_data       = text_data\n",
    "        self.random_cropping = random_cropping\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.audio_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        result_text  = self.text_data[idx]\n",
    "            \n",
    "        result_audio = self.audio_data[idx]\n",
    "        #print(result_audio.shape)\n",
    "        result_audio = np.swapaxes(result_audio, 0,2)\n",
    "        \n",
    "        if self.random_cropping:\n",
    "            start = np.random.randint(0, 880 - 216 + 1)\n",
    "            stop  = start + 216\n",
    "            result_audio = result_audio[:,start:stop,:]\n",
    "        else:\n",
    "            result_audio = result_audio[:,100:316,:]\n",
    "            \n",
    "        result_audio = torch.from_numpy(result_audio).float()\n",
    "        result_text  = torch.from_numpy(result_text).float()\n",
    "        \n",
    "        return result_audio, result_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "#device1 = torch.device(\"cuda:0\")\n",
    "#device1 = torch.device(\"cpu\")\n",
    "device1 = torch.device(\"cuda:0\")\n",
    "#cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model_single = NetKim2019()\n",
    "\n",
    "model = nn.DataParallel(model_single, device_ids = [0,1,2,3])\n",
    "model = model.to(device1)\n",
    "\n",
    "# loss\n",
    "criterion = OnlineTripletLoss(args.margin, args.uppersim).to(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = NetKim2019()\n",
    "model = model.to(device1)\n",
    "\n",
    "# loss\n",
    "criterion = OnlineTripletLoss(args.margin, args.uppersim).to(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learnrate, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# this approach uses an intermediate batchsize. forward passes will be made using this batchsize. \n",
    "# loss is calculated for each intermediate batch. When the number of precessed instances reaches the\n",
    "# globally supplied batchsize, losses are accumulated and backpropagated.\n",
    "\n",
    "INTERMEDIATE_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Train Data Loader\n",
    "dataset_train    = MelSpecDataset(data_audio_train, \n",
    "                                  data_relcontent_train, \n",
    "                                  random_cropping=True)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              batch_size  = INTERMEDIATE_BATCH_SIZE,\n",
    "                              shuffle     = True, \n",
    "                              num_workers = 8)\n",
    "\n",
    "# Validation Data Loader\n",
    "dataset_val      = MelSpecDataset(data_audio_val, \n",
    "                                  data_relcontent_val, \n",
    "                                  random_cropping=False)\n",
    "\n",
    "dataloader_val   = DataLoader(dataset_val, \n",
    "                              batch_size  = INTERMEDIATE_BATCH_SIZE,\n",
    "                              shuffle     = False, \n",
    "                              num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c6c15481ea445fa2d0494d832b477f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=10.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf93cba8645d48e7af5afc2c61be3d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990e42bc7ec04f42b033e8ed79f99c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[train_loss: 0.0, val_loss: nan]', max=248.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n",
      "torch.Size([1000, 128]) torch.Size([1000, 340])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-10012f030c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlocal_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlocal_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_audio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mlocal_text\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlocal_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbar_outer  = tqdm(total=args.epochs, desc='Epoch', position=0)\n",
    "pbar_status = tqdm(total=0, position=1, bar_format='{desc}')\n",
    "\n",
    "current_val_loss = float('nan')\n",
    "running_loss     = 0.0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    \n",
    "    pbar_inner = tqdm(total    = np.ceil(dataset_train.__len__() / args.batchsize).astype(int), \n",
    "                      desc     = f'[train_loss: {running_loss}, val_loss: {current_val_loss}]', \n",
    "                      position = 1)\n",
    "    \n",
    "    running_loss                   = 0.0\n",
    "    current_batch_num              = 0\n",
    "    current_batch_size             = 0\n",
    "    current_batch_audio_embeddings = []\n",
    "    current_batch_text_embeddings  = []\n",
    "   \n",
    "\n",
    "    for local_audio, local_text in dataloader_train:\n",
    "        \n",
    "        local_audio = local_audio.to(device1)\n",
    "        local_text  = local_text.to(device1)\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(local_audio)\n",
    "        \n",
    "        #outputs = outputs.to(device2)\n",
    "        \n",
    "        current_batch_audio_embeddings.append(outputs)\n",
    "        current_batch_text_embeddings.append(local_text)\n",
    "        \n",
    "        current_batch_size += outputs.shape[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if current_batch_size >= args.batchsize:\n",
    "            \n",
    "            audio_embeddings = torch.cat(current_batch_audio_embeddings, dim=0)\n",
    "            text_embeddings  = torch.cat(current_batch_text_embeddings,  dim=0)\n",
    "            \n",
    "            print(audio_embeddings.shape, text_embeddings.shape)\n",
    "            \n",
    "            loss    = criterion.forward(audio_embeddings, text_embeddings)\n",
    "            \n",
    "            #loss    = loss.to(device1)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            current_batch_audio_embeddings.clear()\n",
    "            current_batch_text_embeddings.clear()\n",
    "        \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            pbar_status.set_description_str(f'[train_loss: {loss.item()}, val_loss: {current_val_loss}]')\n",
    "            \n",
    "            pbar_inner.update(1)\n",
    "            \n",
    "            #print('[%d, %5d] loss: %.3f' % (epoch + 1, current_batch_num + 1, running_loss / 1))\n",
    "            \n",
    "            current_batch_num += 1\n",
    "            current_batch_size = 0\n",
    "            \n",
    "\n",
    "            #break\n",
    "    \n",
    "    pbar_outer.update(1)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "INTERMEDIATE_BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Train Data Loader\n",
    "dataset_train    = MelSpecDataset(data_audio_train, \n",
    "                                  data_relcontent_train, \n",
    "                                  random_cropping=True)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              batch_size  = INTERMEDIATE_BATCH_SIZE,\n",
    "                              shuffle     = True, \n",
    "                              num_workers = 8)\n",
    "\n",
    "# Validation Data Loader\n",
    "dataset_val      = MelSpecDataset(data_audio_val, \n",
    "                                  data_relcontent_val, \n",
    "                                  random_cropping=False)\n",
    "\n",
    "dataloader_val   = DataLoader(dataset_val, \n",
    "                              batch_size  = INTERMEDIATE_BATCH_SIZE,\n",
    "                              shuffle     = False, \n",
    "                              num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7bfc0336984988973c9ef1ffe74fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=10.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f6fb695e9942039d5d590f0e66f0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06bc5ac25f545e2983fca911b52f303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[train_loss: 0.0, val_loss: nan]', max=248.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cb1b808a4749398d8f554c52b90a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[train_loss: 252.88746333122253, val_loss: 1.002861976623…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b265e3868a124850acdada565a91540c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[train_loss: 252.89887011051178, val_loss: 1.002861976623…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b2e2f6b7c440b380d1fefceb8bff59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[train_loss: 252.89372265338898, val_loss: 1.002861976623…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ae3e4cff704e65a5da9d3f8c5fe427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[train_loss: 252.88127291202545, val_loss: 1.002861976623…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "AssertionError: can only join a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "Traceback (most recent call last):\n",
      "AssertionError: can only join a child process\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "AssertionError: can only join a child process\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "Traceback (most recent call last):\n",
      "    self._shutdown_workers()\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "    w.join()\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "AssertionError: can only join a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b81fb0f7a94dfbbf5648a1a03f0757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[train_loss: 252.89334642887115, val_loss: 1.002861976623…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "Traceback (most recent call last):\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "AssertionError: can only join a child process\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "AssertionError: can only join a child process\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    self._shutdown_workers()\n",
      "AssertionError: can only join a child process\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "Traceback (most recent call last):\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "AssertionError: can only join a child process\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "Traceback (most recent call last):\n",
      "AssertionError: can only join a child process\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f4ce13520d45be8a8f439762a48424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[train_loss: 252.90145683288574, val_loss: 1.002861976623…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "Traceback (most recent call last):\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "AssertionError: can only join a child process\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    w.join()\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "Traceback (most recent call last):\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "AssertionError: can only join a child process\n",
      "    self._shutdown_workers()\n",
      "    w.join()\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    w.join()\n",
      "Traceback (most recent call last):\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "AssertionError: can only join a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    self._shutdown_workers()\n",
      "AssertionError: can only join a child process\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    self._shutdown_workers()\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "AssertionError: can only join a child process\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526c3bb8a8c14c58b87d7c497ae42163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[train_loss: 252.8718148469925, val_loss: 1.0028619766235…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "Traceback (most recent call last):\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    w.join()\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "    self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    w.join()\n",
      "AssertionError: can only join a child process\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "    self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    w.join()\n",
      "    self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    w.join()\n",
      "AssertionError: can only join a child process\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f88733c6898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/schindlera/.conda/envs/base36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    }
   ],
   "source": [
    "pbar_outer  = tqdm(total=args.epochs, desc='Epoch', position=0)\n",
    "pbar_status = tqdm(total=0, position=1, bar_format='{desc}')\n",
    "\n",
    "current_val_loss = float('nan')\n",
    "running_loss     = 0.0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    \n",
    "    pbar_inner = tqdm(total    = np.ceil(dataset_train.__len__() / args.batchsize).astype(int), \n",
    "                      desc     = f'[train_loss: {running_loss}, val_loss: {current_val_loss}]', \n",
    "                      position = 1)\n",
    "    \n",
    "    running_loss                   = 0.0\n",
    "    current_batch_num              = 0\n",
    "    current_batch_size             = 0\n",
    "    current_batch_audio_embeddings = []\n",
    "    current_batch_text_embeddings  = []\n",
    "   \n",
    "    model.train()\n",
    "\n",
    "    for local_audio, local_text in dataloader_train:\n",
    "        \n",
    "        local_audio = local_audio.to(device1)\n",
    "        local_text  = local_text.to(device1)\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(local_audio)\n",
    "                    \n",
    "        loss    = criterion.forward(outputs, local_text)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar_status.set_description_str(f'[train_loss: {loss.item()}, val_loss: {current_val_loss}]')\n",
    "            \n",
    "        pbar_inner.update(1)\n",
    "            \n",
    "        current_batch_num += 1\n",
    "        current_batch_size = 0\n",
    "            \n",
    "            \n",
    "    model.eval()\n",
    "\n",
    "    for local_audio, local_text in dataloader_val:\n",
    "        \n",
    "        local_audio = local_audio.to(device1)\n",
    "        local_text  = local_text.to(device1)\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(local_audio)\n",
    "                    \n",
    "        loss    = criterion.forward(outputs, local_text)\n",
    "        \n",
    "        current_val_loss = loss.item()\n",
    "\n",
    "    pbar_outer.update(1)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1710646003484726"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 128])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 11:02:52 - experiment.py - INFO - * Prepare Evaluation\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_def' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-64ad6b455fb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinaldim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"* Model created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_def' is not defined"
     ]
    }
   ],
   "source": [
    "        \n",
    "# ===============================================================================\n",
    "# # Train Model\n",
    "# ===============================================================================\n",
    "\n",
    "logger.info(\"* Prepare Evaluation\")\n",
    "\n",
    "# ===============================================================================\n",
    "# ### Build and Train Model\n",
    "# ===============================================================================\n",
    "\n",
    "# define the model\n",
    "model = model_def.get_model(args.finaldim)\n",
    "logger.info(\"* Model created\")\n",
    "\n",
    "# define the optimizer\n",
    "opt = Adam(lr=args.learnrate)\n",
    "logger.info(\"* Optimizer: %s\" % (str(opt)))\n",
    "\n",
    "\n",
    "#from keras_radam import RAdam\n",
    "\n",
    "#opt = RAdam(total_steps=10000, warmup_proportion=0.1, learning_rate=1e-4, min_lr=1e-5)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss      = triplet_loss,\n",
    "              optimizer = opt)\n",
    "logger.info(\"* Model compiled\")\n",
    "                    \n",
    "# ===============================================================================\n",
    "# Callbacks\n",
    "# ===============================================================================\n",
    "\n",
    "cb_modelcheckpoint = ModelCheckpoint(args.modeldir + \"/model.h5\", \n",
    "                                    monitor           = 'val_loss', \n",
    "                                    verbose           = 1, \n",
    "                                    save_best_only    = True, \n",
    "                                    save_weights_only = True, \n",
    "                                    mode              = 'auto')\n",
    "    \n",
    "cb_tensorboard =  TensorBoard(log_dir=args.modeldir, \n",
    "                                histogram_freq=0, \n",
    "                                write_graph=False, \n",
    "                                write_grads=False, \n",
    "                                write_images=False, \n",
    "                                embeddings_freq=0, \n",
    "                                embeddings_layer_names=None, \n",
    "                                embeddings_metadata=None, \n",
    "                                embeddings_data=None, \n",
    "                                update_freq='epoch')\n",
    "\n",
    "cb_csv_logger = CSVLogger(args.modeldir + \"/model_training_log.csv\", separator=';', append=False)\n",
    "\n",
    "cb_logger = LoggerCallback()\n",
    "    \n",
    "callbacks = [cb_tensorboard, cb_modelcheckpoint, cb_csv_logger, cb_logger]\n",
    "logger.info(\"* Callbacks created\")\n",
    "\n",
    "\n",
    "logger.info(\"* Model Training: starting\")\n",
    "# first test - only to debug code\n",
    "history = model.fit(audio_train,\n",
    "                    text_train, \n",
    "                    batch_size       = args.batchsize, \n",
    "                    verbose          = 1, \n",
    "                    epochs           = args.epochs,\n",
    "                    validation_data  = (audio_val, text_val),\n",
    "                    callbacks        = callbacks,\n",
    "                    shuffle          = True);\n",
    "\n",
    "logger.info(\"* Model Training: completed\")\n",
    "\n",
    "model_path = args.modeldir + \"/model.h5\"\n",
    "logger.info(\"* Loading best model: %s\" % model_path)\n",
    "model.load_weights(model_path)\n",
    "\n",
    "logger.info(\"* Inference: Embedding audio data into learned representation\")\n",
    "embeddings = model.predict(data_audio, batch_size=100, verbose=1)\n",
    "\n",
    "logger.info(\"* storing embeddings\")\n",
    "np.savez(args.modeldir + \"/final_embeddings.npz\", data=embeddings, track_ids=lookup_audio.index.values)\n",
    "\n",
    "logger.info(\"* Experiment finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base36",
   "language": "python",
   "name": "base36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
