{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "config = [\n",
    "    \n",
    "\"--experimentdir\", \"/home/schindlera/experiments/ismir2020_reviews/\",\n",
    "\"--modeldir\"     , \"/home/schindlera/experiments/ismir2020_reviews/\",\n",
    "    \n",
    "\"--relcontent\"   , \"rel_content_emb_tag_lsi\", \n",
    "\"--audio\"        , \"melspec_128_10seconds_2ch\", \n",
    "    \n",
    "\"--model\"        , \"model.m1_3\",     \n",
    "\"--gpu\"          , \"0\",\n",
    "    \n",
    "\"--loss\"         , \"original\", \n",
    "\"--lossagg\"      , \"max\", \n",
    "\"--margin\"       , \"1.0\", \n",
    "\"--uppersim\"     , \"0.99\", \n",
    "    \n",
    "\"--finaldim\"     , \"128\", \n",
    "\"--epochs\"       , \"500\", \n",
    "\"--learnrate\"    , \"1e-06\",\n",
    "\"--batchsize\"    , \"3600\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--relcontent',    type=str)\n",
    "parser.add_argument('--model',         type=str)\n",
    "parser.add_argument('--audio',         type=str)\n",
    "parser.add_argument('--experimentdir', type=str)\n",
    "parser.add_argument('--modeldir',      type=str)\n",
    "parser.add_argument('--gpu',           type=int)\n",
    "parser.add_argument('--finaldim',      type=int)\n",
    "parser.add_argument('--lossagg',       type=str, default=\"min\")\n",
    "parser.add_argument('--loss',          type=str, default=\"original\")\n",
    "parser.add_argument('--batchsize',     type=int, default=1000)\n",
    "parser.add_argument('--margin',        type=float)\n",
    "parser.add_argument('--learnrate',     type=float, default=0.0001)\n",
    "parser.add_argument('--uppersim',      type=float)\n",
    "parser.add_argument('--epochs',        type=int, default=100)\n",
    "parser.add_argument(\"--log-level\", default=logging.DEBUG, type=lambda x: getattr(logger, x), help=\"Configure the logger level.\")\n",
    "\n",
    "if sys.argv[0].find(\"ipykernel_launcher\") != -1:\n",
    "    args = parser.parse_args(config)\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# control random processes\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def prepare_model_dir(model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Initialize Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Init Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21 09:44:31 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-21 09:44:31 - experiment.py - INFO - | STARTING EXPERIMENT                                              |\n",
      "2020-04-21 09:44:31 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-21 09:44:31 - experiment.py - INFO - Logger initialized\n",
      "2020-04-21 09:44:31 - experiment.py - INFO - Initializing model experiment directory\n",
      "2020-04-21 09:44:31 - experiment.py - INFO - Initializing logger filehandler\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(\"experiment.py\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| STARTING EXPERIMENT                                              |\")\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"Logger initialized\")\n",
    "\n",
    "logger.info(\"Initializing model experiment directory\")\n",
    "model_storage_path = prepare_model_dir(args.modeldir)\n",
    "\n",
    "logger.info(\"Initializing logger filehandler\")\n",
    "fh = logging.FileHandler(\"%s/experiment.log\" % args.modeldir)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Print Experiment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21 09:44:35 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | EXPERIMENT:                                                      |\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Experiment directory              : /home/schindlera/experiments/ismir2020_reviews/\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Model-Directory                   : /home/schindlera/experiments/ismir2020_reviews/\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Related content filename          : rel_content_emb_tag_lsi\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Audio-Features filename           : melspec_128_10seconds_2ch\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | GPU                               : 0\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Precision                         : double precision\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Model                             : model.m1_3\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Dimensions Final Music-Embeddings : 128\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Loss                              : original\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Loss-Aggregation                  : max\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Upper Sim                         : 0.990000\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Margin                            : 1.000000\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Learn Rate                        : 0.000001\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Batch Size                        : 3600\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - | Num Epochs                        : 500\n",
      "2020-04-21 09:44:35 - experiment.py - INFO - +------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| EXPERIMENT:                                                      |\")\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Experiment directory              : %s\"           % args.experimentdir)\n",
    "logger.info(\"| Model-Directory                   : %s\"           % args.modeldir)\n",
    "logger.info(\"| Related content filename          : %s\"           % args.relcontent)\n",
    "logger.info(\"| Audio-Features filename           : %s\"           % args.audio)\n",
    "logger.info(\"| GPU                               : %d\"           % args.gpu)\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Model                             : %s\"           % args.model)\n",
    "logger.info(\"| Dimensions Final Music-Embeddings : %d\"           % args.finaldim)\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Loss                              : %s\"           % args.loss)\n",
    "logger.info(\"| Loss-Aggregation                  : %s\"           % args.lossagg)\n",
    "logger.info(\"| Upper Sim                         : %f\"           % args.uppersim)\n",
    "logger.info(\"| Margin                            : %f\"           % args.margin)\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Learn Rate                        : %f\"           % args.learnrate)\n",
    "logger.info(\"| Batch Size                        : %d\"           % args.batchsize)\n",
    "logger.info(\"| Num Epochs                        : %d\"           % args.epochs)\n",
    "logger.info(\"+------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Store configuration for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open(\"%s/experiment_arguments.json\" % args.modeldir, 'w') as json_file:\n",
    "    args_json = json.dump(vars(args), json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21 10:07:17 - experiment.py - INFO - * Load Audio Data\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"* Load Audio Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Load Audio Data - Train Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21 10:15:57 - experiment.py - INFO - * Load Audio Data - Train Partition\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a9cafa886536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar_filename_audio_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnpz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata_audio_train\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mnpz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrack_ids_audio_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"track_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                     array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[0;32m--> 779\u001b[0;31m                                                              count=read_count)\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfortran_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger.info(\"* Load Audio Data - Train Partition\")\n",
    "\n",
    "# load partition trackid file\n",
    "par_file           = \"%s/eval_partition_trackids_train.csv\" % (args.experimentdir)\n",
    "par_trackids_train = pd.read_csv(par_file, header=None, index_col=0)\n",
    "\n",
    "# load audio content\n",
    "par_filename_audio_train = \"%s/%s_train.npz\" % (args.experimentdir, args.audio)\n",
    "\n",
    "with np.load(par_filename_audio_train, allow_pickle=True) as npz:\n",
    "    data_audio_train      = npz[\"data\"]\n",
    "    track_ids_audio_train = npz[\"track_ids\"].astype(str)\n",
    "    \n",
    "lookup_audio_train = pd.DataFrame(np.arange(track_ids_audio_train.shape[0], dtype=int), \n",
    "                                  index   = track_ids_audio_train, \n",
    "                                  columns = [\"feature_line_nr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# CHECK: ids and data have same length\n",
    "assert(data_audio_train.shape[0] == track_ids_audio_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Load Audio Data - Validation Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logger.info(\"* Load Audio Data - Validation Partition\")\n",
    "\n",
    "# load partition trackid file\n",
    "par_file         = \"%s/eval_partition_trackids_val.csv\" % (args.experimentdir)\n",
    "par_trackids_val = pd.read_csv(par_file, header=None, index_col=0)\n",
    "\n",
    "# load audio content\n",
    "par_filename_audio_val = \"%s/%s_val.npz\" % (args.experimentdir, args.audio)\n",
    "\n",
    "with np.load(par_filename_audio_val, allow_pickle=True) as npz:\n",
    "    data_audio_val      = npz[\"data\"]\n",
    "    track_ids_audio_val = npz[\"track_ids\"].astype(str)\n",
    "    \n",
    "lookup_audio_val = pd.DataFrame(np.arange(track_ids_audio_val.shape[0], dtype=int), \n",
    "                                  index   = track_ids_audio_val, \n",
    "                                  columns = [\"feature_line_nr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# CHECK: ids and data have same length\n",
    "assert(data_audio_val.shape[0] == track_ids_audio_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logger.info(\"Num instances - audio data train : %d\" % str(data_audio_train.shape[0]))\n",
    "logger.info(\"Num instances - audio data val   : %d\" % str(data_audio_val.shape[0]))\n",
    "\n",
    "logger.debug(\"data_audio dimensions     : %s\" % str(data_audio_train.shape))\n",
    "logger.debug(\"track_ids_audio dimensions: %s\" % str(track_ids_audio_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Related Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logger.info(\"* Load Related Content Embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-10 12:35:57 - experiment.py - INFO - * Load Audio Data\n",
      "2020-04-10 12:45:03 - experiment.py - DEBUG - data_audio dimensions     : (249681, 128, 880, 2)\n",
      "2020-04-10 12:45:03 - experiment.py - DEBUG - track_ids_audio dimensions: (249681,)\n",
      "2020-04-10 12:45:03 - experiment.py - INFO - * Load Text Embeddings\n"
     ]
    }
   ],
   "source": [
    "with np.load(args.text, allow_pickle=True) as npz:\n",
    "    data_text      = npz[\"data\"]\n",
    "    track_ids_text = npz[\"track_ids\"].astype(str)\n",
    "\n",
    "lookup_text = pd.DataFrame(np.arange(track_ids_text.shape[0], dtype=int), index=track_ids_text, columns=[\"feature_line_nr\"])\n",
    "\n",
    "# CHECK: ids and data have same length\n",
    "assert(data_text.shape[0] == track_ids_text.shape[0])\n",
    "\n",
    "# CHECK: ids of text and audio are aligned\n",
    "assert((track_ids_text == track_ids_audio).sum() == track_ids_audio.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-10 12:45:04 - experiment.py - DEBUG - data_text dimensions      : (249681, 128)\n",
      "2020-04-10 12:45:04 - experiment.py - DEBUG - text_ids_audio dimensions : (249681,)\n",
      "2020-04-10 12:45:04 - experiment.py - INFO - TEXT_EMBEDDINGS_DIMENSIONS : 128\n",
      "2020-04-10 12:45:05 - experiment.py - INFO - normalize audio data\n",
      "2020-04-10 12:45:05 - experiment.py - INFO - creating partitions: train/val\n"
     ]
    }
   ],
   "source": [
    "logger.debug(\"data_text dimensions      : %s\" % str(data_text.shape))\n",
    "logger.debug(\"text_ids_audio dimensions : %s\" % str(track_ids_audio.shape))\n",
    "logger.info(\"TEXT_EMBEDDINGS_DIMENSIONS : %d\" % data_text.shape[1])\n",
    "    \n",
    "TEXT_EMBEDDINGS_DIMENSIONS = data_text.shape[1]\n",
    "\n",
    "experiment_partition = pd.read_csv(\"/home/schindlera/experiments/representation_from_album_review/experiment_partition.csv\", index_col=0)\n",
    "\n",
    "\n",
    "logger.info(\"normalize audio data\")\n",
    "\n",
    "#data_audio = data_audio / -80.0\n",
    "#data_audio = data_audio - data_audio.mean()\n",
    "\n",
    "\n",
    "logger.info(\"creating partitions: train/val\")\n",
    "\n",
    "#print(lookup_audio.loc[experiment_partition[experiment_partition.train == 1].index].feature_line_nr.values)\n",
    "\n",
    "audio_train = data_audio[lookup_audio.loc[experiment_partition[experiment_partition.train == 1].index].feature_line_nr.values]\n",
    "audio_val   = data_audio[lookup_audio.loc[experiment_partition[experiment_partition.val   == 1].index].feature_line_nr.values]\n",
    "\n",
    "text_train  = data_text[lookup_text.loc[experiment_partition[experiment_partition.train == 1].index].feature_line_nr.values]\n",
    "text_val    = data_text[lookup_text.loc[experiment_partition[experiment_partition.val   == 1].index].feature_line_nr.values]\n",
    "\n",
    "logger.debug(\"audio_train dimensions    : %s\" % str(audio_train.shape))\n",
    "logger.debug(\"text_train  dimensions    : %s\" % str(text_train.shape))\n",
    "logger.debug(\"audio_val   dimensions    : %s\" % str(audio_val.shape))\n",
    "logger.debug(\"text_val    dimensions    : %s\" % str(text_val.shape))\n",
    "\n",
    "# CHECK: train text and audio have same length\n",
    "assert(audio_train.shape[0] == text_train.shape[0])\n",
    "# CHECK: validation text and audio have same length\n",
    "assert(audio_val.shape[0] == text_val.shape[0])\n",
    "\n",
    "del track_ids_audio, track_ids_text, data_text, experiment_partition, lookup_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Translate Keras / Tensorflow code to PyTroch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class OnlineTripletLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, margin, upper_limit):\n",
    "        super(OnlineTripletLoss, self).__init__()\n",
    "        \n",
    "        self.margin      = margin\n",
    "        self.upper_limit = upper_limit\n",
    "\n",
    "    def cosine_similarity(self, x1, x2=None, eps=1e-8):\n",
    "        x2 = x1 if x2 is None else x2\n",
    "        w1 = x1.norm(p=2, dim=1, keepdim=True)\n",
    "        w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\n",
    "        return torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)\n",
    "\n",
    "    def forward(self, audio_embeddings, text_embdeeings):\n",
    "\n",
    "        # Get the pairwise distance matrix\n",
    "        pairwise_dists_text  = self.cosine_similarity(text_embdeeings)\n",
    "        pairwise_dists_audio = torch.cdist(audio_embeddings,audio_embeddings, p=2)\n",
    "\n",
    "        # create filter masks\n",
    "        max_pairwise_dist_audio = pairwise_dists_audio.max()\n",
    "\n",
    "        # positive bool mask\n",
    "        mask_positive = (pairwise_dists_text.fill_diagonal_(0) > self.upper_limit).float()\n",
    "\n",
    "        # negative bool mask\n",
    "        mask_negative = (1 - mask_positive).fill_diagonal_(0)\n",
    "\n",
    "        if args.lossagg == \"max\":\n",
    "\n",
    "            audio_positive_dist       = pairwise_dists_audio * mask_positive\n",
    "            hardest_positive_dist, _  = audio_positive_dist.max(dim=1, keepdims=True)\n",
    "\n",
    "        #elif args.lossagg == \"min\":\n",
    "        # \n",
    "        #    audio_positive_dist       = pairwise_dists_audio * mask_positive_bool\n",
    "        #    hardest_positive_dist, _  = audio_positive_dist.min(dim=1, keepdims=True)\n",
    "\n",
    "        # negative\n",
    "        max_audio_negative_dist, _ = pairwise_dists_audio.max(1, keepdim=True)\n",
    "        audio_negative_dist        = pairwise_dists_audio + max_audio_negative_dist * (1.0 - mask_negative)\n",
    "\n",
    "        hardest_negative_dist, _   = audio_negative_dist.min(dim=1, keepdims=True)\n",
    "\n",
    "        # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "        delta = hardest_positive_dist - hardest_negative_dist\n",
    "\n",
    "\n",
    "        if   args.loss == \"original\"     : \n",
    "            triplet_loss = (delta + self.margin)\n",
    "            triplet_loss[triplet_loss < 0] = 0\n",
    "            triplet_loss = triplet_loss.mean()\n",
    "\n",
    "\n",
    "        #elif args.loss == \"logistic_sum\" : triplet_loss = tf.reduce_sum (tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "        #elif args.loss == \"logistic_mean\": triplet_loss = tf.reduce_mean(tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "        #elif args.loss == \"hinge_sum\"    : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.nn.relu(margin + delta)))\n",
    "        #elif args.loss == \"hinge_mean\"   : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.nn.relu(margin + delta)))\n",
    "        #elif args.loss == \"exp_sum\"      : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "        #elif args.loss == \"exp_mean\"     : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "        else: raise NotImplementedError\n",
    "\n",
    "        return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NetKim2019(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NetKim2019, self).__init__()\n",
    "        \n",
    "        self.conv1      = nn.Conv2d(2,    16, kernel_size=5, stride=(2,1), padding=2)\n",
    "        self.conv2      = nn.Conv2d(16,   32, kernel_size=3, padding=1)\n",
    "        self.conv3      = nn.Conv2d(32,   64, kernel_size=3, padding=1)\n",
    "        self.conv4      = nn.Conv2d(64,   64, kernel_size=3, padding=1)\n",
    "        self.conv5      = nn.Conv2d(64,  128, kernel_size=3, padding=1)\n",
    "        self.conv6a     = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6b     = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.maxpool1   = nn.MaxPool2d((2,2))\n",
    "        self.maxpool2   = nn.MaxPool2d((2,2))\n",
    "        self.maxpool3   = nn.MaxPool2d((2,2))\n",
    "        self.maxpool4   = nn.MaxPool2d((2,2))\n",
    "        self.maxpool5   = nn.MaxPool2d((2,2))\n",
    "        \n",
    "        self.gap        = nn.AdaptiveMaxPool2d(1)\n",
    "                \n",
    "        self.dropout    = nn.Dropout()\n",
    "        self.fc_feature = nn.Linear(256, 256)\n",
    "        self.fc_output  = nn.Linear(256, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool5(x)\n",
    "        \n",
    "        x = self.conv6a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6b(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.shape[:2])\n",
    "\n",
    "        x = self.fc_feature(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc_output(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "#summary(model.cuda(), (2, 216, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class MelSpecDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, audio_data, text_data, random_cropping=False):\n",
    "        self.audio_data      = audio_data\n",
    "        self.text_data       = text_data\n",
    "        self.random_cropping = random_cropping\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.audio_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        result_text  = self.text_data[idx]\n",
    "            \n",
    "        result_audio = self.audio_data[idx]\n",
    "        #print(result_audio.shape)\n",
    "        result_audio = np.swapaxes(result_audio, 0,2)\n",
    "        \n",
    "        if self.random_cropping:\n",
    "            start = np.random.randint(0, 880 - 216 + 1)\n",
    "            stop  = start + 216\n",
    "            result_audio = result_audio[:,start:stop,:]\n",
    "        else:\n",
    "            result_audio = result_audio[:,100:316,:]\n",
    "            \n",
    "        result_audio = torch.from_numpy(result_audio).float()\n",
    "        result_text  = torch.from_numpy(result_text).float()\n",
    "        \n",
    "        return result_audio, result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "INTERMEDIATE_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "#cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = NetKim2019()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_dataset    = MelSpecDataset(audio_train, text_train, random_cropping=True)\n",
    "dataloader_train = DataLoader(train_dataset, \n",
    "                              batch_size=INTERMEDIATE_BATCH_SIZE,\n",
    "                              shuffle=True, \n",
    "                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "criterion = OnlineTripletLoss(args.margin, args.uppersim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-05, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 23.65 GiB total capacity; 22.71 GiB already allocated; 17.12 MiB free; 22.79 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-ea22c1e3405e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlocal_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_audio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlocal_text\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlocal_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 23.65 GiB total capacity; 22.71 GiB already allocated; 17.12 MiB free; 22.79 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    \n",
    "    running_loss       = 0.0\n",
    "    current_batch_num  = 0\n",
    "    current_batch_size = 0\n",
    "    current_batch_audio_embeddings = []\n",
    "    current_batch_text_embeddings  = []\n",
    "\n",
    "    for local_audio, local_text in dataloader_train:\n",
    "    \n",
    "    \n",
    "        local_audio = local_audio.to(device)\n",
    "        local_text  = local_text.to(device)\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(local_audio)\n",
    "        \n",
    "        current_batch_audio_embeddings.append(outputs)\n",
    "        current_batch_text_embeddings.append(local_text)\n",
    "        \n",
    "        current_batch_size += outputs.shape[0]\n",
    "        \n",
    "        if current_batch_size >= args.batchsize:\n",
    "            \n",
    "            audio_embeddings = torch.cat(current_batch_audio_embeddings, dim=0)\n",
    "            text_embeddings  = torch.cat(current_batch_text_embeddings,  dim=0)\n",
    "            \n",
    "            loss    = criterion.forward(audio_embeddings, text_embeddings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            current_batch_audio_embeddings.clear()\n",
    "            current_batch_text_embeddings.clear()\n",
    "        \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, current_batch_num + 1, running_loss / 1))\n",
    "            \n",
    "            current_batch_num += 1\n",
    "            current_batch_size = 0\n",
    "            running_loss       = 0.0\n",
    "\n",
    "            break\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9510605335235596"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "        \n",
    "# ===============================================================================\n",
    "# # Train Model\n",
    "# ===============================================================================\n",
    "\n",
    "logger.info(\"* Prepare Evaluation\")\n",
    "\n",
    "# ===============================================================================\n",
    "# ### Build and Train Model\n",
    "# ===============================================================================\n",
    "\n",
    "# define the model\n",
    "model = model_def.get_model(args.finaldim)\n",
    "logger.info(\"* Model created\")\n",
    "\n",
    "# define the optimizer\n",
    "opt = Adam(lr=args.learnrate)\n",
    "logger.info(\"* Optimizer: %s\" % (str(opt)))\n",
    "\n",
    "\n",
    "#from keras_radam import RAdam\n",
    "\n",
    "#opt = RAdam(total_steps=10000, warmup_proportion=0.1, learning_rate=1e-4, min_lr=1e-5)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss      = triplet_loss,\n",
    "              optimizer = opt)\n",
    "logger.info(\"* Model compiled\")\n",
    "                    \n",
    "# ===============================================================================\n",
    "# Callbacks\n",
    "# ===============================================================================\n",
    "\n",
    "cb_modelcheckpoint = ModelCheckpoint(args.modeldir + \"/model.h5\", \n",
    "                                    monitor           = 'val_loss', \n",
    "                                    verbose           = 1, \n",
    "                                    save_best_only    = True, \n",
    "                                    save_weights_only = True, \n",
    "                                    mode              = 'auto')\n",
    "    \n",
    "cb_tensorboard =  TensorBoard(log_dir=args.modeldir, \n",
    "                                histogram_freq=0, \n",
    "                                write_graph=False, \n",
    "                                write_grads=False, \n",
    "                                write_images=False, \n",
    "                                embeddings_freq=0, \n",
    "                                embeddings_layer_names=None, \n",
    "                                embeddings_metadata=None, \n",
    "                                embeddings_data=None, \n",
    "                                update_freq='epoch')\n",
    "\n",
    "cb_csv_logger = CSVLogger(args.modeldir + \"/model_training_log.csv\", separator=';', append=False)\n",
    "\n",
    "cb_logger = LoggerCallback()\n",
    "    \n",
    "callbacks = [cb_tensorboard, cb_modelcheckpoint, cb_csv_logger, cb_logger]\n",
    "logger.info(\"* Callbacks created\")\n",
    "\n",
    "\n",
    "logger.info(\"* Model Training: starting\")\n",
    "# first test - only to debug code\n",
    "history = model.fit(audio_train,\n",
    "                    text_train, \n",
    "                    batch_size       = args.batchsize, \n",
    "                    verbose          = 1, \n",
    "                    epochs           = args.epochs,\n",
    "                    validation_data  = (audio_val, text_val),\n",
    "                    callbacks        = callbacks,\n",
    "                    shuffle          = True);\n",
    "\n",
    "logger.info(\"* Model Training: completed\")\n",
    "\n",
    "model_path = args.modeldir + \"/model.h5\"\n",
    "logger.info(\"* Loading best model: %s\" % model_path)\n",
    "model.load_weights(model_path)\n",
    "\n",
    "logger.info(\"* Inference: Embedding audio data into learned representation\")\n",
    "embeddings = model.predict(data_audio, batch_size=100, verbose=1)\n",
    "\n",
    "logger.info(\"* storing embeddings\")\n",
    "np.savez(args.modeldir + \"/final_embeddings.npz\", data=embeddings, track_ids=lookup_audio.index.values)\n",
    "\n",
    "logger.info(\"* Experiment finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base36",
   "language": "python",
   "name": "base36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
