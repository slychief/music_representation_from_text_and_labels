{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "config = [\n",
    "    \n",
    "\"--experimentdir\", \"/home/schindlera/experiments/ismir2020_reviews/\",\n",
    "\"--modeldir\"     , \"/home/schindlera/experiments/ismir2020_reviews/\",\n",
    "    \n",
    "\"--relcontent\"   , \"rel_content_emb_tag_lsi_debug\", \n",
    "\"--audio\"        , \"melspec_128_10seconds_2ch_norm_debug\", \n",
    "    \n",
    "\"--model\"        , \"kim2019\",     \n",
    "\"--gpu\"          , \"0\",\n",
    "    \n",
    "\"--loss\"         , \"original\", \n",
    "\"--lossagg\"      , \"max\", \n",
    "\"--margin\"       , \"1.0\", \n",
    "\"--uppersim\"     , \"0.90\", \n",
    "\"--lowersim\"     , \"0.85\", \n",
    "    \n",
    "\"--finaldim\"     , \"128\", \n",
    "\"--epochs\"       , \"10\", \n",
    "\"--learnrate\"    , \"0.0001\",\n",
    "\"--batchsize\"    , \"1000\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--relcontent',    type=str)\n",
    "parser.add_argument('--model',         type=str)\n",
    "parser.add_argument('--audio',         type=str)\n",
    "parser.add_argument('--experimentdir', type=str)\n",
    "parser.add_argument('--modeldir',      type=str)\n",
    "parser.add_argument('--gpu',           type=int)\n",
    "parser.add_argument('--finaldim',      type=int)\n",
    "parser.add_argument('--lossagg',       type=str, default=\"min\")\n",
    "parser.add_argument('--loss',          type=str, default=\"original\")\n",
    "parser.add_argument('--batchsize',     type=int, default=1000)\n",
    "parser.add_argument('--margin',        type=float)\n",
    "parser.add_argument('--learnrate',     type=float, default=0.0001)\n",
    "parser.add_argument('--uppersim',      type=float)\n",
    "parser.add_argument('--lowersim',      type=float)\n",
    "parser.add_argument('--epochs',        type=int, default=100)\n",
    "parser.add_argument(\"--log-level\", default=logging.DEBUG, type=lambda x: getattr(logger, x), help=\"Configure the logger level.\")\n",
    "\n",
    "if sys.argv[0].find(\"ipykernel_launcher\") != -1:\n",
    "    args = parser.parse_args(config)\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.model_selection import GroupShuffleSplit, ShuffleSplit\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger\n",
    "from tensorflow.keras.constraints import MinMaxNorm, unit_norm\n",
    "from tensorflow.keras.initializers import he_normal, he_uniform\n",
    "from tensorflow.keras.layers import (ELU, AlphaDropout, AveragePooling2D,\n",
    "                                     BatchNormalization, Concatenate, Conv2D,\n",
    "                                     Dense, Dropout, Flatten, GaussianNoise,\n",
    "                                     GlobalAveragePooling2D, Input, Lambda,\n",
    "                                     LeakyReLU, MaxPooling2D, ReLU,\n",
    "                                     SpatialDropout2D)\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adagrad, Adam, Nadam, RMSprop\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import array_ops, math_ops\n",
    "\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# control random processes\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# import model from definition file\n",
    "from importlib import import_module\n",
    "model_def = import_module(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def prepare_model_dir(model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Initialize Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Init Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 14:59:11 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | STARTING EXPERIMENT                                              |\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - Logger initialized\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - Initializing model experiment directory\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - Initializing logger filehandler\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(\"experiment.py\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| STARTING EXPERIMENT                                              |\")\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"Logger initialized\")\n",
    "\n",
    "logger.info(\"Initializing model experiment directory\")\n",
    "model_storage_path = prepare_model_dir(args.modeldir)\n",
    "\n",
    "logger.info(\"Initializing logger filehandler\")\n",
    "fh = logging.FileHandler(\"%s/experiment.log\" % args.modeldir)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Print Experiment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 14:59:11 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | EXPERIMENT:                                                      |\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Experiment directory              : /home/schindlera/experiments/ismir2020_reviews/\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Model-Directory                   : /home/schindlera/experiments/ismir2020_reviews/\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Related content filename          : rel_content_emb_tag_lsi_debug\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Audio-Features filename           : melspec_128_10seconds_2ch_norm_debug\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | GPU                               : 0\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Model                             : kim2019\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Dimensions Final Music-Embeddings : 128\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Loss                              : original\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Loss-Aggregation                  : max\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Upper Sim                         : 0.900000\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Margin                            : 1.000000\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - +------------------------------------------------------------------+\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Learn Rate                        : 0.000100\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Batch Size                        : 1000\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - | Num Epochs                        : 10\n",
      "2020-04-29 14:59:11 - experiment.py - INFO - +------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| EXPERIMENT:                                                      |\")\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Experiment directory              : %s\"           % args.experimentdir)\n",
    "logger.info(\"| Model-Directory                   : %s\"           % args.modeldir)\n",
    "logger.info(\"| Related content filename          : %s\"           % args.relcontent)\n",
    "logger.info(\"| Audio-Features filename           : %s\"           % args.audio)\n",
    "logger.info(\"| GPU                               : %d\"           % args.gpu)\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Model                             : %s\"           % args.model)\n",
    "logger.info(\"| Dimensions Final Music-Embeddings : %d\"           % args.finaldim)\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Loss                              : %s\"           % args.loss)\n",
    "logger.info(\"| Loss-Aggregation                  : %s\"           % args.lossagg)\n",
    "logger.info(\"| Upper Sim                         : %f\"           % args.uppersim)\n",
    "logger.info(\"| Margin                            : %f\"           % args.margin)\n",
    "logger.info(\"+------------------------------------------------------------------+\")\n",
    "logger.info(\"| Learn Rate                        : %f\"           % args.learnrate)\n",
    "logger.info(\"| Batch Size                        : %d\"           % args.batchsize)\n",
    "logger.info(\"| Num Epochs                        : %d\"           % args.epochs)\n",
    "logger.info(\"+------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Store configuration for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open(\"%s/experiment_arguments.json\" % args.modeldir, 'w') as json_file:\n",
    "    args_json = json.dump(vars(args), json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 14:59:11 - experiment.py - INFO - * Load Audio Data\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"* Load Audio Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Load Audio Data - Train Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 14:59:11 - experiment.py - INFO - * Load Audio Data - Train Partition\n",
      "CPU times: user 10 s, sys: 4.74 s, total: 14.7 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logger.info(\"* Load Audio Data - Train Partition\")\n",
    "\n",
    "# load partition trackid file\n",
    "par_file           = \"%s/eval_partition_trackids_train.csv\" % (args.experimentdir)\n",
    "par_trackids_train = pd.read_csv(par_file, header=None, index_col=0)\n",
    "\n",
    "# load audio content\n",
    "par_filename_audio_train = \"%s/%s_train.npz\" % (args.experimentdir, args.audio)\n",
    "\n",
    "with np.load(par_filename_audio_train, allow_pickle=True) as npz:\n",
    "    data_audio_train      = npz[\"data\"]\n",
    "    track_ids_audio_train = npz[\"track_ids\"].astype(str)\n",
    "    \n",
    "lookup_audio_train = pd.DataFrame(np.arange(track_ids_audio_train.shape[0], dtype=int), \n",
    "                                  index   = track_ids_audio_train, \n",
    "                                  columns = [\"feature_line_nr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# CHECK: ids and data have same length\n",
    "assert(data_audio_train.shape[0] == track_ids_audio_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#par_trackids_train.index.values == track_ids_audio_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Load Audio Data - Validation Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 14:59:33 - experiment.py - INFO - * Load Audio Data - Validation Partition\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"* Load Audio Data - Validation Partition\")\n",
    "\n",
    "# load partition trackid file\n",
    "par_file         = \"%s/eval_partition_trackids_val.csv\" % (args.experimentdir)\n",
    "par_trackids_val = pd.read_csv(par_file, header=None, index_col=0)\n",
    "\n",
    "# load audio content\n",
    "par_filename_audio_val = \"%s/%s_val.npz\" % (args.experimentdir, args.audio)\n",
    "\n",
    "with np.load(par_filename_audio_val, allow_pickle=True) as npz:\n",
    "    data_audio_val      = npz[\"data\"]\n",
    "    track_ids_audio_val = npz[\"track_ids\"].astype(str)\n",
    "    \n",
    "lookup_audio_val = pd.DataFrame(np.arange(track_ids_audio_val.shape[0], dtype=int), \n",
    "                                  index   = track_ids_audio_val, \n",
    "                                  columns = [\"feature_line_nr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# CHECK: ids and data have same length\n",
    "assert(data_audio_val.shape[0] == track_ids_audio_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 14:59:39 - experiment.py - INFO - Num instances - audio data train : 10000\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - Num instances - audio data val   : 2500\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - data_audio dimensions            : (10000, 128, 880, 2)\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Num instances - audio data train : %d\" % data_audio_train.shape[0])\n",
    "logger.info(\"Num instances - audio data val   : %d\" % data_audio_val.shape[0])\n",
    "logger.info(\"data_audio dimensions            : %s\" % str(data_audio_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Related Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 14:59:39 - experiment.py - INFO - * Load Related Content Embeddings\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"* Load Related Content Embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Train Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "par_filename_relcontent_train = \"%s/%s_train.npz\" % (args.experimentdir, args.relcontent)\n",
    "\n",
    "with np.load(par_filename_relcontent_train, allow_pickle=True) as npz:\n",
    "    data_relcontent_train     = npz[\"data\"]\n",
    "    trackids_relcontent_train = npz[\"trackids\"].astype(str)\n",
    "\n",
    "lookup_relcontent_train = pd.DataFrame(np.arange(trackids_relcontent_train.shape[0], dtype=int), \n",
    "                                       index   = trackids_relcontent_train, \n",
    "                                       columns = [\"feature_line_nr\"])\n",
    "\n",
    "# CHECK: ids and data have same length\n",
    "assert(data_relcontent_train.shape[0] == trackids_relcontent_train.shape[0])\n",
    "\n",
    "# CHECK: ids of text and audio are aligned\n",
    "#assert((track_ids_text == track_ids_audio).sum() == track_ids_audio.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Validation Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "par_filename_relcontent_val = \"%s/%s_val.npz\" % (args.experimentdir, args.relcontent)\n",
    "\n",
    "with np.load(par_filename_relcontent_val, allow_pickle=True) as npz:\n",
    "    data_relcontent_val     = npz[\"data\"]\n",
    "    trackids_relcontent_val = npz[\"trackids\"].astype(str)\n",
    "\n",
    "lookup_relcontent_val = pd.DataFrame(np.arange(trackids_relcontent_val.shape[0], dtype=int), \n",
    "                                       index   = trackids_relcontent_val, \n",
    "                                       columns = [\"feature_line_nr\"])\n",
    "\n",
    "# CHECK: ids and data have same length\n",
    "assert(data_relcontent_val.shape[0] == trackids_relcontent_val.shape[0])\n",
    "\n",
    "# CHECK: ids of text and audio are aligned\n",
    "#assert((track_ids_text == track_ids_audio).sum() == track_ids_audio.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 14:59:39 - experiment.py - INFO - Num instances - related content train : 10000\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - Num instances - related content val   : 2500\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - data_relcontent dimensions            : (10000, 340)\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - TEXT_EMBEDDINGS_DIMENSIONS            : 340\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - +------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Num instances - related content train : %d\" % data_relcontent_train.shape[0])\n",
    "logger.info(\"Num instances - related content val   : %d\" % data_relcontent_val.shape[0])\n",
    "logger.info(\"data_relcontent dimensions            : %s\" % str(data_relcontent_train.shape))\n",
    "logger.info(\"TEXT_EMBEDDINGS_DIMENSIONS            : %d\" % data_relcontent_train.shape[1])\n",
    "logger.info(\"+------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 14:59:39 - experiment.py - INFO - Partitions overview - train/val\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - data_audio_train      dimensions    : (10000, 128, 880, 2)\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - data_relcontent_train dimensions    : (10000, 340)\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - data_audio_val        dimensions    : (2500, 128, 880, 2)\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - data_relcontent_val   dimensions    : (2500, 340)\n",
      "2020-04-29 14:59:39 - experiment.py - INFO - +------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "TEXT_EMBEDDINGS_DIMENSIONS = data_relcontent_train.shape[1]\n",
    "\n",
    "logger.info(\"Partitions overview - train/val\")\n",
    "\n",
    "logger.info(\"data_audio_train      dimensions    : %s\" % str(data_audio_train.shape))\n",
    "logger.info(\"data_relcontent_train dimensions    : %s\" % str(data_relcontent_train.shape))\n",
    "logger.info(\"data_audio_val        dimensions    : %s\" % str(data_audio_val.shape))\n",
    "logger.info(\"data_relcontent_val   dimensions    : %s\" % str(data_relcontent_val.shape))\n",
    "logger.info(\"+------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "expDtype = tf.float32\n",
    "epsilon  = 1e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def pairwise_similarity_cosine(feature):\n",
    "\n",
    "    feature            = K.l2_normalize(feature,axis=1)\n",
    "    pairwise_distances = tf.matmul(feature, feature, adjoint_b = True)\n",
    "    \n",
    "    return pairwise_distances\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "def pairwise_distance_euclidean(feature, squared=False):\n",
    "    \"\"\"Computes the pairwise distance matrix with numerical stability.\n",
    "\n",
    "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "\n",
    "    Args:\n",
    "      feature: 2-D Tensor of size [number of data, feature dimension].\n",
    "      squared: Boolean, whether or not to square the pairwise distances.\n",
    "\n",
    "    Returns:\n",
    "      pairwise_distances: 2-D Tensor of size [number of data, number of data].\n",
    "    \"\"\"\n",
    "    pairwise_distances_squared = math_ops.add(\n",
    "        math_ops.reduce_sum(math_ops.square(feature), axis=[1], keepdims=True),\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.square(array_ops.transpose(feature)),\n",
    "            axis=[0],\n",
    "            keepdims=True)) - 2.0 * math_ops.matmul(feature,\n",
    "                                                    array_ops.transpose(feature))\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = math_ops.maximum(pairwise_distances_squared, 0.0)\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = math_ops.less_equal(pairwise_distances_squared, 0.0)\n",
    "\n",
    "    # Optionally take the sqrt.\n",
    "    if squared:\n",
    "        pairwise_distances = pairwise_distances_squared\n",
    "    else:\n",
    "        pairwise_distances = math_ops.sqrt(\n",
    "            pairwise_distances_squared + tf.cast(error_mask, expDtype) * epsilon)\n",
    "\n",
    "    # Undo conditionally adding 1e-16.\n",
    "    pairwise_distances = math_ops.multiply(\n",
    "        pairwise_distances, tf.cast(math_ops.logical_not(error_mask), expDtype))\n",
    "\n",
    "    num_data = array_ops.shape(feature)[0]\n",
    "    # Explicitly set diagonals to zero.\n",
    "    mask_offdiagonals = array_ops.ones_like(pairwise_distances) - array_ops.diag(\n",
    "        array_ops.ones([num_data], dtype=expDtype))\n",
    "    pairwise_distances = math_ops.multiply(pairwise_distances, mask_offdiagonals)\n",
    "    return pairwise_distances\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#%matplotlib inline\n",
    "\n",
    "#sns.heatmap(mask_positive_bool)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "def triplet_loss(text_embdeeings, audio_embeddings):\n",
    "        \n",
    "\n",
    "    #audio_embeddings = embeddings\n",
    "    #audio_embeddings.shape\n",
    "    #text_embdeeings = data_relcontent_train[:100]\n",
    "\n",
    "    #tf.print(audio_embeddings[0])\n",
    "        \n",
    "    # normalize embeddings\n",
    "    audio_embeddings = tf.nn.l2_normalize(audio_embeddings, 1, 1e-10, name='embeddings')\n",
    "    #text_embdeeings  = K.l2_normalize(text_embdeeings  ,axis=1)\n",
    "    \n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dists_text  = pairwise_similarity_cosine(text_embdeeings)\n",
    "    pairwise_dists_audio = tfa.losses.metric_learning.pairwise_distance(audio_embeddings, squared=False)\n",
    "    \n",
    "    # create filter masks\n",
    "    \n",
    "    # utils\n",
    "    diag_zeros = tf.linalg.diag_part(pairwise_dists_text) * 0\n",
    "    diag_false = tf.cast(diag_zeros, tf.bool)\n",
    "    max_pairwise_dists_audio  = tf.reduce_max(pairwise_dists_audio, keepdims=True)\n",
    "    \n",
    "    # positive bool mask\n",
    "    mask_positive_bool = tf.greater(pairwise_dists_text, args.uppersim)\n",
    "    mask_positive_bool = tf.linalg.set_diag(mask_positive_bool, diag_false)\n",
    "    \n",
    "    # negative bool mask\n",
    "    #mask_negative_bool = tf.less(pairwise_dists_text, UPPER_SIM)\n",
    "    #mask_negative_bool = tf.linalg.set_diag(mask_negative_bool, diag_false)    \n",
    "    mask_negative_bool = tf.less(pairwise_dists_text, args.lowersim)\n",
    "    mask_negative_bool = tf.linalg.set_diag(mask_negative_bool, diag_false)    \n",
    "\n",
    "    # positive\n",
    "    mask_positive_float       = tf.cast(mask_positive_bool, dtype=expDtype)\n",
    "    mask_negative_float       = tf.cast(mask_negative_bool, dtype=expDtype)\n",
    "    \n",
    "    if args.lossagg == \"max\":\n",
    "        \n",
    "        audio_positive_dist       = pairwise_dists_audio * mask_positive_float\n",
    "        hardest_positive_dist     = tf.reduce_max(audio_positive_dist, axis=1, keepdims=True)\n",
    "    \n",
    "    elif args.lossagg == \"min\":\n",
    "    \n",
    "        audio_positive_dist       = pairwise_dists_audio + max_pairwise_dists_audio * (1.0 - mask_positive_float)\n",
    "        hardest_positive_dist     = tf.reduce_min(audio_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # negative\n",
    "    #audio_negative_dist       = pairwise_dists_audio + max_pairwise_dists_audio * (1.0 - mask_negative_float)\n",
    "    audio_negative_dist       = pairwise_dists_audio + mask_negative_float\n",
    "    hardest_negative_dist     = tf.reduce_max(audio_negative_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # only use triplets where a positive and negative examples were identified\n",
    "    mask_positive_bool_any    = tf.reduce_any(mask_positive_bool, axis=1, keepdims=True)\n",
    "    mask_negative_bool_any    = tf.reduce_any(mask_negative_bool, axis=1, keepdims=True)\n",
    "        \n",
    "    # final mask\n",
    "    final_mask                = tf.math.logical_and(mask_positive_bool_any, mask_negative_bool_any)\n",
    "    #final_mask = mask_positive_bool_any\n",
    "    \n",
    "    #hardest_positive_dist     = tf.boolean_mask(hardest_positive_dist, final_mask)\n",
    "    #hardest_negative_dist     = tf.boolean_mask(hardest_negative_dist, final_mask)\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    delta               = hardest_positive_dist - hardest_negative_dist\n",
    "\n",
    "    valid_positives     = tf.reduce_max(mask_positive_float, axis=1, keepdims=True)\n",
    "    num_valid_positives = tf.reduce_sum(valid_positives)\n",
    "    \n",
    "    tf.print(num_valid_positives, \n",
    "             tf.reduce_mean(hardest_positive_dist), \n",
    "             tf.reduce_mean(hardest_negative_dist))\n",
    "    \n",
    "    #x = tf.constant(0, name='x')\n",
    "    \n",
    "    #if tf.equal(hardest_positive_dist.shape[0], x):\n",
    "        \n",
    "    #    triplet_loss = 0\n",
    "\n",
    "        \n",
    "    #else:\n",
    "        \n",
    "    \n",
    "    triplet_loss = tf.reduce_mean(tf.maximum(delta + args.margin, 0.0)) # eigentlich auch hinge\n",
    "    #triplet_loss = triplet_loss / num_valid_positives # mean (excluding non valid pairs)\n",
    "\n",
    "    \n",
    "    #if   args.loss == \"original\"     :    \n",
    "    #elif args.loss == \"logistic_sum\" : triplet_loss = tf.reduce_sum (tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "    #elif args.loss == \"logistic_mean\": triplet_loss = tf.reduce_mean(tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "    #elif args.loss == \"hinge_sum\"    : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.nn.relu(args.margin + delta)))\n",
    "    #elif args.loss == \"hinge_mean\"   : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.nn.relu(args.margin + delta)))\n",
    "    #elif args.loss == \"exp_sum\"      : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "    #elif args.loss == \"exp_mean\"     : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "    #else: raise NotImplementedError\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "plt.imshow(mask_negative_bool)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "def _masked_maximum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise maximum over chosen elements.\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the maximum.\n",
    "    Returns:\n",
    "      masked_maximums: N-D `Tensor`.\n",
    "        The maximized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_minimums = tf.math.reduce_min(data, dim, keepdims=True)\n",
    "    masked_maximums = tf.math.reduce_max(\n",
    "        tf.math.multiply(data - axis_minimums, mask), dim,\n",
    "        keepdims=True) + axis_minimums\n",
    "    return masked_maximums\n",
    "\n",
    "\n",
    "def _masked_minimum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise minimum over chosen elements.\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the minimum.\n",
    "    Returns:\n",
    "      masked_minimums: N-D `Tensor`.\n",
    "        The minimized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_maximums = tf.math.reduce_max(data, dim, keepdims=True)\n",
    "    masked_minimums = tf.math.reduce_min(\n",
    "        tf.math.multiply(data - axis_maximums, mask), dim,\n",
    "        keepdims=True) + axis_maximums\n",
    "    return masked_minimums"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "@tf.function\n",
    "def triplet_semihard_loss(y_true, y_pred, margin=1.0):\n",
    "    \"\"\"Computes the triplet loss with semi-hard negative mining.\n",
    "    Args:\n",
    "      y_true: 1-D integer `Tensor` with shape [batch_size] of\n",
    "        multiclass integer labels.\n",
    "      y_pred: 2-D float `Tensor` of embedding vectors. Embeddings should\n",
    "        be l2 normalized.\n",
    "      margin: Float, margin term in the loss definition.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    labels, embeddings = y_true, y_pred\n",
    "\n",
    "    # normalize embeddings\n",
    "    embeddings = tf.nn.l2_normalize(embeddings, 1, 1e-10, name='embeddings')\n",
    "    \n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dists_text  = pairwise_similarity_cosine(labels)\n",
    "    \n",
    "    diag_zeros = tf.linalg.diag_part(pairwise_dists_text) * 0\n",
    "    diag_false = tf.cast(diag_zeros, tf.bool)\n",
    "    \n",
    "    \n",
    "    # positive bool mask\n",
    "    adjacency = tf.greater(pairwise_dists_text, args.uppersim)\n",
    "    #adjacency = tf.linalg.set_diag(adjacency, diag_false)\n",
    "    \n",
    "    adjacency_not = tf.math.logical_not(adjacency)\n",
    "    #adjacency_not = tf.linalg.set_diag(adjacency_not, diag_false)\n",
    "    \n",
    "    # Reshape label tensor to [batch_size, 1].\n",
    "    lshape = tf.shape(labels)\n",
    "    \n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = tfa.losses.metric_learning.pairwise_distance(embeddings, squared=True)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    \n",
    "    batch_size = lshape[0]\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = tf.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = tf.math.logical_and(\n",
    "        tf.tile(adjacency_not, [batch_size, 1]),\n",
    "        tf.math.greater(pdist_matrix_tile,\n",
    "                        tf.reshape(tf.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = tf.reshape(\n",
    "        tf.math.greater(\n",
    "            tf.math.reduce_sum(\n",
    "                tf.cast(mask, dtype=tf.dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    mask_final = tf.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = tf.reshape(\n",
    "        _masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = tf.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = tf.tile(\n",
    "        _masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "    semi_hard_negatives = tf.where(mask_final, negatives_outside,\n",
    "                                   negatives_inside)\n",
    "\n",
    "    loss_mat = tf.math.add(margin, pdist_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = tf.cast(\n",
    "        adjacency, dtype=tf.dtypes.float32) - tf.linalg.diag(\n",
    "            tf.ones([batch_size]))\n",
    "\n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = tf.math.reduce_sum(mask_positives)\n",
    "\n",
    "    triplet_loss = tf.math.truediv(\n",
    "        tf.math.reduce_sum(\n",
    "            tf.math.maximum(tf.math.multiply(loss_mat, mask_positives), 0.0)),\n",
    "        num_positives)\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class LoggerCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        logger.info(\"+------------------------------------------------------------------+\")\n",
    "        logger.info(\"| TRAINING BEGIN                                                   |\")\n",
    "        logger.info(\"+------------------------------------------------------------------+\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logger.info('Epoch %d: train_loss %f - val_loss %f' % (epoch, logs['loss'], logs['val_loss']))\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        logger.info(\"+------------------------------------------------------------------+\")\n",
    "        logger.info(\"| TRAINING END                                                     |\")\n",
    "        logger.info(\"+------------------------------------------------------------------+\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "def get_model(embeddings_dimensions):\n",
    "\n",
    "    # --- input layers\n",
    "    input_eval_model = Input((128,216,2))\n",
    "    \n",
    "    #cropped_input    = RandomCropping2D(cropping=(0,216))(input_eval_model)\n",
    "       \n",
    "    cnn  = Conv2D(16, (5,5), padding=\"same\", kernel_initializer=he_uniform(1), activation=\"relu\", strides=(1,2), name=\"conv1\")(input_eval_model)\n",
    "    cnn = MaxPooling2D((2,2), name=\"max-pool1\")(cnn)\n",
    "    \n",
    "    cnn  = Conv2D(32, (3,3), padding=\"same\", kernel_initializer=he_uniform(2), activation=\"relu\", name=\"conv2\")(cnn)\n",
    "    cnn = MaxPooling2D((2,2), name=\"max-pool2\")(cnn)\n",
    "    \n",
    "    cnn  = Conv2D(64, (3,3), padding=\"same\", kernel_initializer=he_uniform(3), activation=\"relu\", name=\"conv3\")(cnn)\n",
    "    cnn = MaxPooling2D((2,2), name=\"max-pool3\")(cnn)\n",
    "    \n",
    "    cnn  = Conv2D(64, (3,3), padding=\"same\", kernel_initializer=he_uniform(4), activation=\"relu\", name=\"conv4\")(cnn)\n",
    "    cnn = MaxPooling2D((2,2), name=\"max-pool4\")(cnn)\n",
    "    \n",
    "    cnn  = Conv2D(128, (3,3), padding=\"same\", kernel_initializer=he_uniform(5), activation=\"relu\", name=\"conv5\")(cnn)\n",
    "    cnn = MaxPooling2D((2,2), name=\"max-pool5\")(cnn)\n",
    "    \n",
    "    cnn  = Conv2D(128, (3,3), padding=\"same\", kernel_initializer=he_uniform(6), activation=\"relu\", name=\"conv61\")(cnn)\n",
    "    cnn  = Conv2D(256, (1,1), padding=\"same\", kernel_initializer=he_uniform(7), activation=\"relu\", name=\"conv62\")(cnn)\n",
    "    \n",
    "    gap = GlobalAveragePooling2D(name=\"gap\")(cnn)\n",
    "    \n",
    "    out = Dense(256, activation=\"relu\", kernel_initializer=he_uniform(7), name=\"fc-feature\")(gap)\n",
    "    \n",
    "\n",
    "    \n",
    "    #mk2019_out       = Dropout(0.5)(out)\n",
    "    \n",
    "    #fc_output        = Dense(embeddings_dimensions, activation=\"elu\", kernel_initializer=he_uniform(8), name=\"fc-output\")(mk2019_out)\n",
    "    \n",
    "    model_eval      = Model(inputs=[input_eval_model], outputs=out)\n",
    "    \n",
    "    return model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def triplet_loss_soft(text_embdeeings, audio_embeddings):\n",
    "        \n",
    "\n",
    "    #audio_embeddings = embeddings\n",
    "    #audio_embeddings.shape\n",
    "    #text_embdeeings = data_relcontent_train[:100]\n",
    "    \n",
    "    margin = tf.constant(args.margin)\n",
    "\n",
    "    #tf.print(audio_embeddings[0])\n",
    "        \n",
    "    # normalize embeddings\n",
    "    audio_embeddings = tf.nn.l2_normalize(audio_embeddings, 1, 1e-10, name='embeddings')\n",
    "    #text_embdeeings  = K.l2_normalize(text_embdeeings  ,axis=1)\n",
    "    \n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dists_text  = pairwise_similarity_cosine(text_embdeeings)\n",
    "    pairwise_dists_audio = tfa.losses.metric_learning.pairwise_distance(audio_embeddings, squared=False)\n",
    "    \n",
    "    # create filter masks\n",
    "    \n",
    "    # utils\n",
    "    diag_zeros = tf.linalg.diag_part(pairwise_dists_text) * 0\n",
    "    diag_false = tf.cast(diag_zeros, tf.bool)\n",
    "    max_pairwise_dists_audio  = tf.reduce_max(pairwise_dists_audio, keepdims=True)\n",
    "    \n",
    "    # positive bool mask\n",
    "    max_pairwise_dists_text      = tf.reduce_max(pairwise_dists_text, axis=1, keepdims=True)\n",
    "    mask_max_pairwise_dists_text = tf.equal(pairwise_dists_text, max_pairwise_dists_text)\n",
    "    \n",
    "    mask_positive_bool      = tf.greater(pairwise_dists_text, args.uppersim)\n",
    "    mask_positive_bool      = tf.math.logical_and(mask_positive_bool, mask_max_pairwise_dists_text)\n",
    "    \n",
    "    mask_positive_bool      = tf.linalg.set_diag(mask_positive_bool, diag_false)\n",
    "    \n",
    "    # negative bool mask\n",
    "    #mask_negative_bool = tf.less(pairwise_dists_text, UPPER_SIM)\n",
    "    #mask_negative_bool = tf.linalg.set_diag(mask_negative_bool, diag_false)    \n",
    "    mask_negative_bool = tf.less(pairwise_dists_text, args.lowersim)\n",
    "    mask_negative_bool = tf.linalg.set_diag(mask_negative_bool, diag_false)    \n",
    "\n",
    "    # positive\n",
    "    mask_positive_float       = tf.cast(mask_positive_bool, dtype=expDtype)\n",
    "    mask_negative_float       = tf.cast(mask_negative_bool, dtype=expDtype)\n",
    "    \n",
    "    if args.lossagg == \"max\":\n",
    "        \n",
    "        audio_positive_dist       = pairwise_dists_audio * mask_positive_float\n",
    "        hardest_positive_dist     = tf.reduce_max(audio_positive_dist, axis=1, keepdims=True)\n",
    "    \n",
    "    elif args.lossagg == \"min\":\n",
    "    \n",
    "        audio_positive_dist       = pairwise_dists_audio + max_pairwise_dists_audio * (1.0 - mask_positive_float)\n",
    "        hardest_positive_dist     = tf.reduce_min(audio_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # negative\n",
    "    mask_greater_as_hard_pos  = tf.greater(pairwise_dists_audio, hardest_positive_dist)\n",
    "    mask_greater_zero         = tf.greater(pairwise_dists_audio + margin, hardest_positive_dist)\n",
    "    mask_negative_bool        = tf.math.logical_and(mask_negative_bool, mask_greater_as_hard_pos)\n",
    "    mask_negative_bool        = tf.math.logical_and(mask_negative_bool, mask_greater_zero)\n",
    "    mask_negative_float       = tf.cast(mask_negative_bool, dtype=expDtype)\n",
    "    audio_negative_dist       = pairwise_dists_audio + max_pairwise_dists_audio * (1.0 - mask_negative_float)\n",
    "    hardest_negative_dist     = tf.reduce_min(audio_negative_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # only use triplets where a positive and negative examples were identified\n",
    "    #mask_positive_bool_any    = tf.reduce_any(mask_positive_bool, axis=1, keepdims=True)\n",
    "    #mask_negative_bool_any    = tf.reduce_any(mask_negative_bool, axis=1, keepdims=True)\n",
    "        \n",
    "    # final mask\n",
    "    #final_mask                = tf.math.logical_and(mask_positive_bool_any, mask_negative_bool_any)\n",
    "    #final_mask_float          = tf.cast(final_mask, dtype=expDtype)\n",
    "    #final_mask = mask_positive_bool_any\n",
    "    \n",
    "    #hardest_positive_dist     = tf.boolean_mask(hardest_positive_dist, final_mask)\n",
    "    #hardest_negative_dist     = tf.boolean_mask(hardest_negative_dist, final_mask)\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    delta               = hardest_positive_dist - hardest_negative_dist\n",
    "    \n",
    "\n",
    "    #tf.print(\"delta\", delta)\n",
    "    #valid_positives     = tf.reduce_max(mask_positive_float, axis=1, keepdims=True)\n",
    "    #num_valid_positives = tf.reduce_sum(valid_positives)\n",
    "    \n",
    "    #tf.print(num_valid_positives, \n",
    "    #         tf.reduce_mean(hardest_positive_dist), \n",
    "    #         tf.reduce_mean(hardest_negative_dist))\n",
    "    \n",
    "    #x = tf.constant(0, name='x')\n",
    "    \n",
    "    #if tf.equal(hardest_positive_dist.shape[0], x):\n",
    "        \n",
    "    #    triplet_loss = 0\n",
    "\n",
    "        \n",
    "    #else:\n",
    "        \n",
    "    delta_hinge = tf.maximum(delta + margin, 0.0)\n",
    "    \n",
    "    #delta_hinge               = delta_hinge * final_mask_float\n",
    "    \n",
    "    #tf.print(\"delta_hinge\", delta_hinge)\n",
    "    \n",
    "    triplet_loss = tf.reduce_mean(delta_hinge) # eigentlich auch hinge\n",
    "    #triplet_loss = triplet_loss / num_valid_positives # mean (excluding non valid pairs)\n",
    "    \n",
    "    #tf.print(\"triplet_loss\", triplet_loss)\n",
    "\n",
    "    \n",
    "    #if   args.loss == \"original\"     :    \n",
    "    #elif args.loss == \"logistic_sum\" : triplet_loss = tf.reduce_sum (tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "    #elif args.loss == \"logistic_mean\": triplet_loss = tf.reduce_mean(tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "    #elif args.loss == \"hinge_sum\"    : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.nn.relu(args.margin + delta)))\n",
    "    #elif args.loss == \"hinge_mean\"   : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.nn.relu(args.margin + delta)))\n",
    "    #elif args.loss == \"exp_sum\"      : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "    #elif args.loss == \"exp_mean\"     : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "    #else: raise NotImplementedError\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def triplet_loss_hard(text_embdeeings, audio_embeddings):\n",
    "        \n",
    "\n",
    "    #audio_embeddings = embeddings\n",
    "    #audio_embeddings.shape\n",
    "    #text_embdeeings = data_relcontent_train[:100]\n",
    "    \n",
    "    margin = tf.constant(args.margin)\n",
    "\n",
    "    #tf.print(audio_embeddings[0])\n",
    "        \n",
    "    # normalize embeddings\n",
    "    audio_embeddings = tf.nn.l2_normalize(audio_embeddings, 1, 1e-10, name='embeddings')\n",
    "    #text_embdeeings  = K.l2_normalize(text_embdeeings  ,axis=1)\n",
    "    \n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dists_text  = pairwise_similarity_cosine(text_embdeeings)\n",
    "    pairwise_dists_audio = tfa.losses.metric_learning.pairwise_distance(audio_embeddings, squared=False)\n",
    "    \n",
    "    # create filter masks\n",
    "    \n",
    "    # utils\n",
    "    diag_zeros = tf.linalg.diag_part(pairwise_dists_text) * 0\n",
    "    diag_false = tf.cast(diag_zeros, tf.bool)\n",
    "    max_pairwise_dists_audio  = tf.reduce_max(pairwise_dists_audio, keepdims=True)\n",
    "    \n",
    "    # positive bool mask\n",
    "    max_pairwise_dists_text      = tf.reduce_max(pairwise_dists_text, axis=1, keepdims=True)\n",
    "    mask_max_pairwise_dists_text = tf.equal(pairwise_dists_text, max_pairwise_dists_text)\n",
    "    \n",
    "    mask_positive_bool      = tf.greater(pairwise_dists_text, args.uppersim)\n",
    "    mask_positive_bool      = tf.math.logical_and(mask_positive_bool, mask_max_pairwise_dists_text)\n",
    "    \n",
    "    mask_positive_bool      = tf.linalg.set_diag(mask_positive_bool, diag_false)\n",
    "    \n",
    "    # negative bool mask\n",
    "    #mask_negative_bool = tf.less(pairwise_dists_text, UPPER_SIM)\n",
    "    #mask_negative_bool = tf.linalg.set_diag(mask_negative_bool, diag_false)    \n",
    "    mask_negative_bool = tf.less(pairwise_dists_text, args.lowersim)\n",
    "    mask_negative_bool = tf.linalg.set_diag(mask_negative_bool, diag_false)    \n",
    "\n",
    "    # positive\n",
    "    mask_positive_float       = tf.cast(mask_positive_bool, dtype=expDtype)\n",
    "    mask_negative_float       = tf.cast(mask_negative_bool, dtype=expDtype)\n",
    "    \n",
    "    if args.lossagg == \"max\":\n",
    "        \n",
    "        audio_positive_dist       = pairwise_dists_audio * mask_positive_float\n",
    "        hardest_positive_dist     = tf.reduce_max(audio_positive_dist, axis=1, keepdims=True)\n",
    "    \n",
    "    elif args.lossagg == \"min\":\n",
    "    \n",
    "        audio_positive_dist       = pairwise_dists_audio + max_pairwise_dists_audio * (1.0 - mask_positive_float)\n",
    "        hardest_positive_dist     = tf.reduce_min(audio_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # negative\n",
    "    #mask_greater_as_hard_pos  = tf.greater(pairwise_dists_audio, hardest_positive_dist)\n",
    "    #mask_greater_zero         = tf.greater(pairwise_dists_audio + margin, hardest_positive_dist)\n",
    "    #mask_negative_bool        = tf.math.logical_and(mask_negative_bool, mask_greater_as_hard_pos)\n",
    "    #mask_negative_bool        = tf.math.logical_and(mask_negative_bool, mask_greater_zero)\n",
    "    #mask_negative_float       = tf.cast(mask_negative_bool, dtype=expDtype)\n",
    "    audio_negative_dist       = pairwise_dists_audio + max_pairwise_dists_audio * (1.0 - mask_negative_float)\n",
    "    hardest_negative_dist     = tf.reduce_min(audio_negative_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # only use triplets where a positive and negative examples were identified\n",
    "    mask_positive_bool_any    = tf.reduce_any(mask_positive_bool, axis=1, keepdims=True)\n",
    "    mask_negative_bool_any    = tf.reduce_any(mask_negative_bool, axis=1, keepdims=True)\n",
    "        \n",
    "    # final mask\n",
    "    final_mask                = tf.math.logical_and(mask_positive_bool_any, mask_negative_bool_any)\n",
    "    final_mask_float          = tf.cast(final_mask, dtype=expDtype)\n",
    "    #final_mask = mask_positive_bool_any\n",
    "    \n",
    "    #hardest_positive_dist     = tf.boolean_mask(hardest_positive_dist, final_mask)\n",
    "    #hardest_negative_dist     = tf.boolean_mask(hardest_negative_dist, final_mask)\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    delta               = hardest_positive_dist - hardest_negative_dist\n",
    "    \n",
    "\n",
    "    #tf.print(\"delta\", delta)\n",
    "    valid_positives     = tf.reduce_max(mask_positive_float, axis=1, keepdims=True)\n",
    "    num_valid_positives = tf.reduce_sum(valid_positives)\n",
    "    \n",
    "    tf.print(num_valid_positives, \n",
    "             tf.reduce_mean(hardest_positive_dist), \n",
    "             tf.reduce_mean(hardest_negative_dist))\n",
    "    \n",
    "    #x = tf.constant(0, name='x')\n",
    "    \n",
    "    #if tf.equal(hardest_positive_dist.shape[0], x):\n",
    "        \n",
    "    #    triplet_loss = 0\n",
    "\n",
    "        \n",
    "    #else:\n",
    "        \n",
    "    delta_hinge = tf.maximum(delta + margin, 0.0)\n",
    "    \n",
    "    #delta_hinge               = delta_hinge * final_mask_float\n",
    "    \n",
    "    #tf.print(\"delta_hinge\", delta_hinge)\n",
    "    \n",
    "    triplet_loss = tf.reduce_mean(delta_hinge) # eigentlich auch hinge\n",
    "    #triplet_loss = triplet_loss / num_valid_positives # mean (excluding non valid pairs)\n",
    "    \n",
    "    #tf.print(\"triplet_loss\", triplet_loss)\n",
    "\n",
    "    \n",
    "    #if   args.loss == \"original\"     :    \n",
    "    #elif args.loss == \"logistic_sum\" : triplet_loss = tf.reduce_sum (tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "    #elif args.loss == \"logistic_mean\": triplet_loss = tf.reduce_mean(tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "    #elif args.loss == \"hinge_sum\"    : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.nn.relu(args.margin + delta)))\n",
    "    #elif args.loss == \"hinge_mean\"   : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.nn.relu(args.margin + delta)))\n",
    "    #elif args.loss == \"exp_sum\"      : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "    #elif args.loss == \"exp_mean\"     : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "    #else: raise NotImplementedError\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def triplet_loss_soft(text_embdeeings, audio_embeddings):\n",
    "        \n",
    "\n",
    "    #audio_embeddings = embeddings\n",
    "    #audio_embeddings.shape\n",
    "    #text_embdeeings = data_relcontent_train[:100]\n",
    "        \n",
    "    margin = tf.constant(args.margin)\n",
    "\n",
    "    #tf.print(audio_embeddings[0])\n",
    "        \n",
    "    # normalize embeddings\n",
    "    audio_embeddings = tf.nn.l2_normalize(audio_embeddings, 1, 1e-10, name='embeddings')\n",
    "    #text_embdeeings  = K.l2_normalize(text_embdeeings  ,axis=1)\n",
    "\n",
    "    emb_a = audio_embeddings[:100,:]\n",
    "    emb_p = audio_embeddings[100:200,:]\n",
    "    \n",
    "    tf.print(emb_a.shape, emb_p.shape)\n",
    "    \n",
    "    hardest_positive_dist  =  tf.sqrt(tf.reduce_sum(tf.pow(emb_a - emb_p, 2), axis=1))\n",
    "    \n",
    "    tf.print(hardest_positive_dist.shape)\n",
    "    tf.print(hardest_positive_dist)\n",
    "    \n",
    "    # Get the pairwise distance matrix\n",
    "    #pairwise_dists_text  = pairwise_similarity_cosine(text_embdeeings)\n",
    "    pairwise_dists_audio = tfa.losses.metric_learning.pairwise_distance(audio_embeddings, squared=False)\n",
    "    \n",
    "    # create filter masks\n",
    "    \n",
    "    # utils\n",
    "    diag_zeros = tf.linalg.diag_part(pairwise_dists_audio) * 0\n",
    "    diag_false = tf.cast(diag_zeros, tf.bool)\n",
    "    max_pairwise_dists_audio  = tf.reduce_max(pairwise_dists_audio, keepdims=True)\n",
    "    \n",
    "    # positive bool mask\n",
    "    #max_pairwise_dists_text      = tf.reduce_max(pairwise_dists_text, axis=1, keepdims=True)\n",
    "    #mask_max_pairwise_dists_text = tf.equal(pairwise_dists_text, max_pairwise_dists_text)\n",
    "    \n",
    "    #mask_positive_bool      = tf.greater(pairwise_dists_text, args.uppersim)\n",
    "    #mask_positive_bool      = tf.math.logical_and(mask_positive_bool, mask_max_pairwise_dists_text)\n",
    "    \n",
    "    #mask_positive_bool      = tf.linalg.set_diag(mask_positive_bool, diag_false)\n",
    "    \n",
    "    # negative bool mask\n",
    "    #mask_negative_bool = tf.less(pairwise_dists_text, UPPER_SIM)\n",
    "    #mask_negative_bool = tf.linalg.set_diag(mask_negative_bool, diag_false)    \n",
    "    #mask_negative_bool = tf.less(pairwise_dists_text, args.lowersim)\n",
    "    #mask_negative_bool = tf.linalg.set_diag(mask_negative_bool, diag_false)    \n",
    "\n",
    "    # positive\n",
    "    #mask_positive_float       = tf.cast(mask_positive_bool, dtype=expDtype)\n",
    "    #mask_negative_float       = tf.cast(mask_negative_bool, dtype=expDtype)\n",
    "    \n",
    "    #if args.lossagg == \"max\":\n",
    "    #    \n",
    "    #    audio_positive_dist       = pairwise_dists_audio * mask_positive_float\n",
    "    #    hardest_positive_dist     = tf.reduce_max(audio_positive_dist, axis=1, keepdims=True)\n",
    "    \n",
    "    #elif args.lossagg == \"min\":\n",
    "    \n",
    "    #    audio_positive_dist       = pairwise_dists_audio + max_pairwise_dists_audio * (1.0 - mask_positive_float)\n",
    "    #    hardest_positive_dist     = tf.reduce_min(audio_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # negative\n",
    "    mask_greater_as_hard_pos  = tf.greater(pairwise_dists_audio[:100], hardest_positive_dist)\n",
    "    mask_greater_zero         = tf.greater(pairwise_dists_audio[:100] + margin, hardest_positive_dist)\n",
    "    mask_negative_bool        = tf.math.logical_and(mask_greater_zero, mask_greater_as_hard_pos)\n",
    "    #mask_negative_bool        = tf.math.logical_and(mask_negative_bool, mask_greater_zero)\n",
    "    mask_negative_float       = tf.cast(mask_negative_bool, dtype=expDtype)\n",
    "    audio_negative_dist       = pairwise_dists_audio + max_pairwise_dists_audio * (1.0 - mask_negative_float)\n",
    "    hardest_negative_dist     = tf.reduce_min(audio_negative_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # only use triplets where a positive and negative examples were identified\n",
    "    #mask_positive_bool_any    = tf.reduce_any(mask_positive_bool, axis=1, keepdims=True)\n",
    "    #mask_negative_bool_any    = tf.reduce_any(mask_negative_bool, axis=1, keepdims=True)\n",
    "        \n",
    "    # final mask\n",
    "    #final_mask                = tf.math.logical_and(mask_positive_bool_any, mask_negative_bool_any)\n",
    "    #final_mask_float          = tf.cast(final_mask, dtype=expDtype)\n",
    "    #final_mask = mask_positive_bool_any\n",
    "    \n",
    "    #hardest_positive_dist     = tf.boolean_mask(hardest_positive_dist, final_mask)\n",
    "    #hardest_negative_dist     = tf.boolean_mask(hardest_negative_dist, final_mask)\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    delta               = hardest_positive_dist - hardest_negative_dist\n",
    "    \n",
    "\n",
    "    #tf.print(\"delta\", delta)\n",
    "    #valid_positives     = tf.reduce_max(mask_positive_float, axis=1, keepdims=True)\n",
    "    #num_valid_positives = tf.reduce_sum(valid_positives)\n",
    "    \n",
    "    #tf.print(num_valid_positives, \n",
    "    #         tf.reduce_mean(hardest_positive_dist), \n",
    "    #         tf.reduce_mean(hardest_negative_dist))\n",
    "    \n",
    "    #x = tf.constant(0, name='x')\n",
    "    \n",
    "    #if tf.equal(hardest_positive_dist.shape[0], x):\n",
    "        \n",
    "    #    triplet_loss = 0\n",
    "\n",
    "        \n",
    "    #else:\n",
    "        \n",
    "    delta_hinge = tf.maximum(delta + margin, 0.0)\n",
    "    \n",
    "    #delta_hinge               = delta_hinge * final_mask_float\n",
    "    \n",
    "    #tf.print(\"delta_hinge\", delta_hinge)\n",
    "    \n",
    "    triplet_loss = tf.reduce_mean(delta_hinge) # eigentlich auch hinge\n",
    "    #triplet_loss = triplet_loss / num_valid_positives # mean (excluding non valid pairs)\n",
    "    \n",
    "    #tf.print(\"triplet_loss\", triplet_loss)\n",
    "\n",
    "    \n",
    "    #if   args.loss == \"original\"     :    \n",
    "    #elif args.loss == \"logistic_sum\" : triplet_loss = tf.reduce_sum (tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "    #elif args.loss == \"logistic_mean\": triplet_loss = tf.reduce_mean(tf.log1p(tf.reduce_sum(tf.exp(delta), axis=2)))\n",
    "    #elif args.loss == \"hinge_sum\"    : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.nn.relu(args.margin + delta)))\n",
    "    #elif args.loss == \"hinge_mean\"   : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.nn.relu(args.margin + delta)))\n",
    "    #elif args.loss == \"exp_sum\"      : triplet_loss = tf.reduce_sum (tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "    #elif args.loss == \"exp_mean\"     : triplet_loss = tf.reduce_mean(tf.reduce_sum(tf.exp(delta), axis=2))\n",
    "    #else: raise NotImplementedError\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 15:14:23 - experiment.py - INFO - * Prepare Evaluation\n",
      "2020-04-29 15:14:23 - experiment.py - INFO - * Model created\n",
      "2020-04-29 15:14:23 - experiment.py - INFO - * Optimizer: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f20f43d7898>\n",
      "2020-04-29 15:14:23 - experiment.py - INFO - * Model compiled\n",
      "2020-04-29 15:14:23 - experiment.py - INFO - * Callbacks created\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# # Train Model\n",
    "# ===============================================================================\n",
    "\n",
    "logger.info(\"* Prepare Evaluation\")\n",
    "\n",
    "# ===============================================================================\n",
    "# ### Build and Train Model\n",
    "# ===============================================================================\n",
    "\n",
    "# define the model\n",
    "model = model_def.get_model(args.finaldim)\n",
    "\n",
    "logger.info(\"* Model created\")\n",
    "\n",
    "# define the optimizer\n",
    "opt = Adam(lr=args.learnrate)\n",
    "#opt = SGD(lr=0.0001)\n",
    "#opt = tfa.optimizers.RectifiedAdam(lr=1e-4)\n",
    "\n",
    "logger.info(\"* Optimizer: %s\" % (str(opt)))\n",
    "\n",
    "\n",
    "#from keras_radam import RAdam\n",
    "\n",
    "#opt = RAdam(total_steps=10000, warmup_proportion=0.1, learning_rate=1e-4, min_lr=1e-5)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss      = triplet_loss_soft,\n",
    "              optimizer = opt)\n",
    "logger.info(\"* Model compiled\")\n",
    "                    \n",
    "# ===============================================================================\n",
    "# Callbacks\n",
    "# ===============================================================================\n",
    "\n",
    "cb_modelcheckpoint = ModelCheckpoint(args.modeldir + \"/model.h5\", \n",
    "                                    monitor           = 'val_loss', \n",
    "                                    verbose           = 1, \n",
    "                                    save_best_only    = True, \n",
    "                                    save_weights_only = True, \n",
    "                                    mode              = 'auto')\n",
    "    \n",
    "cb_tensorboard =  TensorBoard(log_dir=args.modeldir, \n",
    "                                histogram_freq=0, \n",
    "                                write_graph=False, \n",
    "                                write_grads=False, \n",
    "                                write_images=False, \n",
    "                                embeddings_freq=0, \n",
    "                                embeddings_layer_names=None, \n",
    "                                embeddings_metadata=None, \n",
    "                                embeddings_data=None, \n",
    "                                update_freq='epoch')\n",
    "\n",
    "cb_csv_logger = CSVLogger(args.modeldir + \"/model_training_log.csv\", separator=';', append=False)\n",
    "\n",
    "cb_logger = LoggerCallback()\n",
    "    \n",
    "callbacks = [cb_tensorboard, \n",
    "             cb_modelcheckpoint, \n",
    "             cb_csv_logger, \n",
    "             cb_logger]\n",
    "logger.info(\"* Callbacks created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 128, 880, 2), (300, 340))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\n",
    "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, audio, relcontent, batch_size=32, shuffle=True):\n",
    "\n",
    "        self.audio      = audio\n",
    "        self.relcontent = relcontent\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle    = shuffle\n",
    "        self.sample_size = int(self.batch_size / 3)\n",
    "        \n",
    "        self.indexes    = np.arange(self.audio.shape[0])\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.indexes.shape[0] / (self.sample_size)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        sample_idx_orig = self.indexes[index * self.sample_size:(index + 1) * self.sample_size]\n",
    "\n",
    "        triplet_indexes = self._get_indexes(sample_idx_orig)\n",
    "        \n",
    "        return self.audio[triplet_indexes], self.relcontent[triplet_indexes]\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _get_indexes(self, sample_idx_orig):\n",
    "        \n",
    "        sample_size_large = self.sample_size * 10\n",
    "        \n",
    "        #print(sample_size_large)\n",
    "        \n",
    "        sample_idx = np.random.randint(0,self.relcontent.shape[0], sample_size_large)\n",
    "        sample_idx = np.setdiff1d(sample_idx, sample_idx_orig)[:sample_size_large - self.sample_size]\n",
    "        sample_idx = np.concatenate([sample_idx_orig, sample_idx], axis=0)\n",
    "\n",
    "        sample     = self.relcontent[sample_idx]\n",
    "\n",
    "        sample_cossim    = 1 - cdist(sample, sample, metric='cosine')\n",
    "        np.fill_diagonal(sample_cossim, 0)\n",
    "\n",
    "        max_sample_idx_a = np.arange(sample_idx.shape[0])\n",
    "\n",
    "        max_sample       = sample_cossim.max(axis=1)\n",
    "        max_sample_idx_p = sample_cossim.argmax(axis=1)\n",
    "\n",
    "        anchor_positive_pairs = np.asarray([max_sample_idx_a, max_sample_idx_p]).T\n",
    "        #print(anchor_positive_pairs.shape, max_sample.shape)\n",
    "        anchor_positive_pairs = anchor_positive_pairs[max_sample >= args.uppersim]\n",
    "\n",
    "        np.sort(anchor_positive_pairs, axis=1)\n",
    "\n",
    "        anchor_positive_pairs = np.unique(anchor_positive_pairs, axis=0)\n",
    "\n",
    "        for j in [0,1]:\n",
    "\n",
    "            valid_indexes = []\n",
    "            last_val = -1\n",
    "\n",
    "            for i in np.argsort(anchor_positive_pairs[:,j]):\n",
    "\n",
    "                #print(last_val, anchor_positive_pairs[i,j])\n",
    "                if anchor_positive_pairs[i,j] != last_val:\n",
    "                    valid_indexes.append(i)\n",
    "                    last_val = anchor_positive_pairs[i,j]\n",
    "\n",
    "            anchor_positive_pairs = anchor_positive_pairs[valid_indexes]\n",
    "\n",
    "        anchor_positive_pairs = anchor_positive_pairs[:self.sample_size]\n",
    "\n",
    "        negative_samples = sample_cossim[anchor_positive_pairs[:,0]] * (sample_cossim[anchor_positive_pairs[:,0]] < args.lowersim)\n",
    "\n",
    "        unique_indexes = anchor_positive_pairs.flatten().tolist()\n",
    "\n",
    "        max_sample_idx_n = []\n",
    "\n",
    "        for i in range(negative_samples.shape[0]):\n",
    "\n",
    "            sorted_indexes = np.argsort(negative_samples[i,:])[::-1]\n",
    "\n",
    "            for idx in sorted_indexes:\n",
    "                if idx not in unique_indexes:\n",
    "                    max_sample_idx_n.append(idx)\n",
    "                    unique_indexes.append(idx)\n",
    "                    break\n",
    "\n",
    "        triplets = np.concatenate([anchor_positive_pairs, np.expand_dims(max_sample_idx_n, axis=1)], axis=1)\n",
    "\n",
    "        batch_idx = sample_idx[triplets.flatten()]\n",
    "        \n",
    "        return batch_idx\n",
    "\n",
    "\n",
    "train_datagenerator = DataGenerator(data_audio_train, data_relcontent_train, batch_size=300)\n",
    "x,y = train_datagenerator.__getitem__(1)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagenerator.__len__()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "sample_idx = np.random.randint(0,data_relcontent_train.shape[0], 1000)\n",
    "sample_idx = np.setdiff1d(sample_idx, sample_idx_orig)[:900]\n",
    "sample_idx = np.concatenate([sample_idx_orig, sample_idx], axis=0)\n",
    "\n",
    "#sample_anchors = data_relcontent_train[sample_idx_orig]\n",
    "sample     = data_relcontent_train[sample_idx]\n",
    "\n",
    "sample_cossim    = 1 - cdist(sample, sample, metric='cosine')\n",
    "np.fill_diagonal(sample_cossim, 0)\n",
    "\n",
    "max_sample_idx_a = np.arange(1000)\n",
    "\n",
    "max_sample       = sample_cossim.max(axis=1)\n",
    "max_sample_idx_p = sample_cossim.argmax(axis=1)\n",
    "\n",
    "anchor_positive_pairs = np.asarray([max_sample_idx_a, max_sample_idx_p]).T\n",
    "anchor_positive_pairs = anchor_positive_pairs[max_sample >= 0.9]\n",
    "\n",
    "np.sort(anchor_positive_pairs, axis=1)\n",
    "\n",
    "anchor_positive_pairs = np.unique(anchor_positive_pairs, axis=0)\n",
    "\n",
    "for j in [0,1]:\n",
    "    \n",
    "    valid_indexes = []\n",
    "    last_val = -1\n",
    "    \n",
    "    for i in np.argsort(anchor_positive_pairs[:,j]):\n",
    "\n",
    "        #print(last_val, anchor_positive_pairs[i,j])\n",
    "        if anchor_positive_pairs[i,j] != last_val:\n",
    "            valid_indexes.append(i)\n",
    "            last_val = anchor_positive_pairs[i,j]\n",
    "            \n",
    "    anchor_positive_pairs = anchor_positive_pairs[valid_indexes]\n",
    "\n",
    "anchor_positive_pairs = anchor_positive_pairs[:100]\n",
    "\n",
    "negative_samples = sample_cossim[anchor_positive_pairs[:,0]] * (sample_cossim[anchor_positive_pairs[:,0]] < 0.9)\n",
    "\n",
    "unique_indexes = anchor_positive_pairs.flatten().tolist()\n",
    "\n",
    "max_sample_idx_n = []\n",
    "\n",
    "for i in range(negative_samples.shape[0]):\n",
    "    \n",
    "    sorted_indexes = np.argsort(negative_samples[i,:])[::-1]\n",
    "    \n",
    "    for idx in sorted_indexes:\n",
    "        if idx not in unique_indexes:\n",
    "            max_sample_idx_n.append(idx)\n",
    "            unique_indexes.append(idx)\n",
    "            break\n",
    "            \n",
    "triplets = np.concatenate([anchor_positive_pairs, np.expand_dims(max_sample_idx_n, axis=1)], axis=1)\n",
    "\n",
    "batch_idx = sample_idx[triplets.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(loss      = triplet_loss_soft,\n",
    "              optimizer = opt)\n",
    "\n",
    "args.epochs = 100"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "model.compile(loss      = triplet_loss_hard,\n",
    "              optimizer = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logger.info(\"* Model Training: starting\")\n",
    "# first test - only to debug code\n",
    "history = model.fit(data_audio_train,#[:,:,:216,:],\n",
    "                    data_relcontent_train, \n",
    "                    batch_size       = args.batchsize, \n",
    "                    verbose          = 1, \n",
    "                    epochs           = args.epochs,\n",
    "                    validation_data  = (data_audio_val, data_relcontent_val),\n",
    "                    #callbacks        = callbacks,\n",
    "                    shuffle          = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 15:14:28 - experiment.py - INFO - * Model Training: starting\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "TensorShape([None, 128]) TensorShape([None, 128])\n",
      "TensorShape([None])\n",
      "[0.967394292 1.15343618 0.79336822 ... 0.945726633 0.878512 0.997563839]\n",
      "  1/100 [..............................] - ETA: 2:20"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [100,300] vs. [100]\n\t [[node loss/fc-output_loss/Greater (defined at <ipython-input-41-61c80d406068>:67) ]] [Op:__inference_distributed_function_6863]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node loss/fc-output_loss/Greater:\n loss/fc-output_loss/Sqrt (defined at <ipython-input-41-61c80d406068>:21)\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-29ad53e91589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_audio_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_relcontent_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0;31m#callbacks        = callbacks,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     shuffle          = True);\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/.conda/envs/base36/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [100,300] vs. [100]\n\t [[node loss/fc-output_loss/Greater (defined at <ipython-input-41-61c80d406068>:67) ]] [Op:__inference_distributed_function_6863]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node loss/fc-output_loss/Greater:\n loss/fc-output_loss/Sqrt (defined at <ipython-input-41-61c80d406068>:21)\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"* Model Training: starting\")\n",
    "# first test - only to debug code\n",
    "history = model.fit(train_datagenerator, \n",
    "                    #batch_size       = 300, \n",
    "                    verbose          = 1, \n",
    "                    epochs           = args.epochs,\n",
    "                    validation_data  = (data_audio_val, data_relcontent_val),\n",
    "                    #callbacks        = callbacks,\n",
    "                    shuffle          = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 128, 216, 2)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 128, 108, 16)      816       \n",
      "_________________________________________________________________\n",
      "max-pool1 (MaxPooling2D)     (None, 64, 54, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 64, 54, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max-pool2 (MaxPooling2D)     (None, 32, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 32, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max-pool3 (MaxPooling2D)     (None, 16, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 16, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max-pool4 (MaxPooling2D)     (None, 8, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 8, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max-pool5 (MaxPooling2D)     (None, 4, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv61 (Conv2D)              (None, 4, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv62 (Conv2D)              (None, 4, 3, 256)         33024     \n",
      "_________________________________________________________________\n",
      "gap (GlobalAveragePooling2D) (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc-feature (Dense)           (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc-output (Dense)            (None, 128)               32896     \n",
      "=================================================================\n",
      "Total params: 414,032\n",
      "Trainable params: 414,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "embeddings = model.predict(data_audio_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6054550e80>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.62554065e-04, -1.57725811e-03,  7.92967994e-03, ...,\n",
       "        -3.34244967e-03,  8.70856456e-04, -3.12542915e-03],\n",
       "       [ 1.22367323e-03, -2.40933895e-03,  1.14681767e-02, ...,\n",
       "        -3.78507376e-03,  3.25050205e-03, -3.87662649e-03],\n",
       "       [ 6.35376084e-04, -4.83119488e-03,  1.23331705e-02, ...,\n",
       "        -2.72279978e-03,  3.71459406e-03, -3.79580259e-03],\n",
       "       ...,\n",
       "       [ 1.34877989e-03, -1.91712379e-03,  1.04327453e-02, ...,\n",
       "        -2.84612179e-03,  2.95229629e-03, -2.12794542e-03],\n",
       "       [ 1.96444523e-03, -1.90186501e-03,  1.19501995e-02, ...,\n",
       "        -3.82292271e-03,  3.23392986e-03, -2.96080112e-03],\n",
       "       [-8.31484795e-05, -6.47127628e-03,  1.20019028e-02, ...,\n",
       "        -4.43172455e-03,  4.06207191e-03, -4.24808264e-03]], dtype=float32)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "logger.info(\"* Model Training: completed\")\n",
    "\n",
    "model_path = args.modeldir + \"/model.h5\"\n",
    "logger.info(\"* Loading best model: %s\" % model_path)\n",
    "model.load_weights(model_path)\n",
    "\n",
    "logger.info(\"* Inference: Embedding audio data into learned representation\")\n",
    "embeddings = model.predict(data_audio, batch_size=100, verbose=1)\n",
    "\n",
    "logger.info(\"* storing embeddings\")\n",
    "np.savez(args.modeldir + \"/final_embeddings.npz\", data=embeddings, track_ids=lookup_audio.index.values)\n",
    "\n",
    "logger.info(\"* Experiment finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base36",
   "language": "python",
   "name": "base36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
